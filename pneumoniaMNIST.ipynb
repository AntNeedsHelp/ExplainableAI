{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AntNeedsHelp/ExplainableAI/blob/main/pneumoniaMNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQ6kMdLBp_QG",
        "outputId": "665f713b-0af6-4c8d-9fba-78b7b154245d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu117\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.0.2+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.27.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (17.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Collecting medmnist\n",
            "  Downloading medmnist-2.2.3-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from medmnist) (1.23.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from medmnist) (1.5.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from medmnist) (1.2.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from medmnist) (0.19.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from medmnist) (4.66.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from medmnist) (9.4.0)\n",
            "Collecting fire (from medmnist)\n",
            "  Downloading fire-0.5.0.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from medmnist) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from medmnist) (0.15.2+cu118)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire->medmnist) (1.16.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->medmnist) (2.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist) (2023.3.post1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (1.11.3)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (3.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (2.31.5)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (2023.9.26)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (1.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (23.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->medmnist) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->medmnist) (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (1.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->medmnist) (3.27.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->medmnist) (17.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->medmnist) (2.31.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->medmnist) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->medmnist) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->medmnist) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->medmnist) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->medmnist) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->medmnist) (1.3.0)\n",
            "Building wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116934 sha256=77a7dfa85a97bfd56e81a4fd560171340cca68462198bba857ee36f08e5b843f\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/d4/f7/9404e5db0116bd4d43e5666eaa3e70ab53723e1e3ea40c9a95\n",
            "Successfully built fire\n",
            "Installing collected packages: fire, medmnist\n",
            "Successfully installed fire-0.5.0 medmnist-2.2.3\n"
          ]
        }
      ],
      "source": [
        "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117\n",
        "!pip3 install medmnist"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "\n",
        "import medmnist\n",
        "from medmnist import INFO, Evaluator"
      ],
      "metadata": {
        "id": "BSrND7ZzqOKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBElYCdAm7V6",
        "outputId": "440524b7-edc8-41c3-b827-81d52f8813bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.1+cu118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_flag = 'pneumoniamnist'\n",
        "# data_flag = 'breastmnist'\n",
        "download = True\n",
        "\n",
        "NUM_EPOCHS = 3\n",
        "BATCH_SIZE = 128\n",
        "lr = 0.001\n",
        "\n",
        "info = INFO[data_flag]\n",
        "task = info['task']\n",
        "n_channels = info['n_channels']\n",
        "n_classes = len(info['label'])\n",
        "\n",
        "DataClass = getattr(medmnist, info['python_class'])"
      ],
      "metadata": {
        "id": "WWSdBCJUqjyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocessing\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[.5], std=[.5])\n",
        "])\n",
        "\n",
        "# load the data\n",
        "train_dataset = DataClass(split='train', transform=data_transform, download=download)\n",
        "test_dataset = DataClass(split='test', transform=data_transform, download=download)\n",
        "\n",
        "pil_dataset = DataClass(split='train', download=download)\n",
        "\n",
        "# encapsulate data into dataloader form\n",
        "train_loader = data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = data.DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "for X, y in test_loader:\n",
        "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
        "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JgC3z80rL5F",
        "outputId": "9071de1e-9ec6-471f-8836-50f9b1775df9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://zenodo.org/record/6496656/files/pneumoniamnist.npz?download=1 to /root/.medmnist/pneumoniamnist.npz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4170669/4170669 [00:01<00:00, 2802845.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using downloaded and verified file: /root/.medmnist/pneumoniamnist.npz\n",
            "Using downloaded and verified file: /root/.medmnist/pneumoniamnist.npz\n",
            "Shape of X [N, C, H, W]: torch.Size([128, 1, 28, 28])\n",
            "Shape of y: torch.Size([128, 1]) torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get cpu, gpu or mps device for training.\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "# Define model\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6j1VbiN-rPac",
        "outputId": "bd92fee3-007a-450e-bcde-cc3aa640a1b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "nP-SSQqjr9aM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader, model, loss_fn, optimizer, print_size=1):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        y = torch.squeeze(y)\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if batch % print_size == 0:\n",
        "            loss, current = loss.item(), (batch + 1) * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
      ],
      "metadata": {
        "id": "kZH_hfdvshPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            y = torch.squeeze(y)\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.5f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "metadata": {
        "id": "Agg6Y87ksmWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ACTUAL TRAINING LOOP"
      ],
      "metadata": {
        "id": "cIAQHKvEsMJ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 500\n",
        "\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_loader, model, loss_fn, optimizer, 5)\n",
        "    test(test_loader, model, loss_fn)\n",
        "print(\"Done!\")\n",
        "%time"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxSmNCb_sslk",
        "outputId": "e28f9adb-5419-4d13-9e10-5bc789f9b0f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "loss: 1.848199  [ 3968/ 4708]\n",
            "loss: 1.830573  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 117\n",
            "-------------------------------\n",
            "loss: 1.871376  [  128/ 4708]\n",
            "loss: 1.840435  [  768/ 4708]\n",
            "loss: 1.836169  [ 1408/ 4708]\n",
            "loss: 1.865576  [ 2048/ 4708]\n",
            "loss: 1.865241  [ 2688/ 4708]\n",
            "loss: 1.856660  [ 3328/ 4708]\n",
            "loss: 1.850268  [ 3968/ 4708]\n",
            "loss: 1.840552  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 118\n",
            "-------------------------------\n",
            "loss: 1.837656  [  128/ 4708]\n",
            "loss: 1.828368  [  768/ 4708]\n",
            "loss: 1.847940  [ 1408/ 4708]\n",
            "loss: 1.841873  [ 2048/ 4708]\n",
            "loss: 1.808964  [ 2688/ 4708]\n",
            "loss: 1.845094  [ 3328/ 4708]\n",
            "loss: 1.873782  [ 3968/ 4708]\n",
            "loss: 1.831878  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 119\n",
            "-------------------------------\n",
            "loss: 1.847891  [  128/ 4708]\n",
            "loss: 1.833639  [  768/ 4708]\n",
            "loss: 1.844619  [ 1408/ 4708]\n",
            "loss: 1.803481  [ 2048/ 4708]\n",
            "loss: 1.894447  [ 2688/ 4708]\n",
            "loss: 1.843706  [ 3328/ 4708]\n",
            "loss: 1.879195  [ 3968/ 4708]\n",
            "loss: 1.818489  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 120\n",
            "-------------------------------\n",
            "loss: 1.802408  [  128/ 4708]\n",
            "loss: 1.869851  [  768/ 4708]\n",
            "loss: 1.850192  [ 1408/ 4708]\n",
            "loss: 1.843669  [ 2048/ 4708]\n",
            "loss: 1.855495  [ 2688/ 4708]\n",
            "loss: 1.846752  [ 3328/ 4708]\n",
            "loss: 1.852830  [ 3968/ 4708]\n",
            "loss: 1.863611  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 121\n",
            "-------------------------------\n",
            "loss: 1.862722  [  128/ 4708]\n",
            "loss: 1.858065  [  768/ 4708]\n",
            "loss: 1.839430  [ 1408/ 4708]\n",
            "loss: 1.829708  [ 2048/ 4708]\n",
            "loss: 1.843721  [ 2688/ 4708]\n",
            "loss: 1.857619  [ 3328/ 4708]\n",
            "loss: 1.876710  [ 3968/ 4708]\n",
            "loss: 1.826866  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 122\n",
            "-------------------------------\n",
            "loss: 1.823506  [  128/ 4708]\n",
            "loss: 1.875081  [  768/ 4708]\n",
            "loss: 1.845167  [ 1408/ 4708]\n",
            "loss: 1.837972  [ 2048/ 4708]\n",
            "loss: 1.871308  [ 2688/ 4708]\n",
            "loss: 1.858007  [ 3328/ 4708]\n",
            "loss: 1.840221  [ 3968/ 4708]\n",
            "loss: 1.831840  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 123\n",
            "-------------------------------\n",
            "loss: 1.823105  [  128/ 4708]\n",
            "loss: 1.875511  [  768/ 4708]\n",
            "loss: 1.854290  [ 1408/ 4708]\n",
            "loss: 1.823218  [ 2048/ 4708]\n",
            "loss: 1.856386  [ 2688/ 4708]\n",
            "loss: 1.828918  [ 3328/ 4708]\n",
            "loss: 1.853849  [ 3968/ 4708]\n",
            "loss: 1.862716  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 124\n",
            "-------------------------------\n",
            "loss: 1.844889  [  128/ 4708]\n",
            "loss: 1.851117  [  768/ 4708]\n",
            "loss: 1.835591  [ 1408/ 4708]\n",
            "loss: 1.867804  [ 2048/ 4708]\n",
            "loss: 1.828353  [ 2688/ 4708]\n",
            "loss: 1.849132  [ 3328/ 4708]\n",
            "loss: 1.840397  [ 3968/ 4708]\n",
            "loss: 1.816893  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 125\n",
            "-------------------------------\n",
            "loss: 1.860179  [  128/ 4708]\n",
            "loss: 1.831715  [  768/ 4708]\n",
            "loss: 1.885292  [ 1408/ 4708]\n",
            "loss: 1.852309  [ 2048/ 4708]\n",
            "loss: 1.852064  [ 2688/ 4708]\n",
            "loss: 1.849269  [ 3328/ 4708]\n",
            "loss: 1.849775  [ 3968/ 4708]\n",
            "loss: 1.816109  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 126\n",
            "-------------------------------\n",
            "loss: 1.879259  [  128/ 4708]\n",
            "loss: 1.826392  [  768/ 4708]\n",
            "loss: 1.855411  [ 1408/ 4708]\n",
            "loss: 1.866407  [ 2048/ 4708]\n",
            "loss: 1.837328  [ 2688/ 4708]\n",
            "loss: 1.848612  [ 3328/ 4708]\n",
            "loss: 1.826792  [ 3968/ 4708]\n",
            "loss: 1.837372  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 127\n",
            "-------------------------------\n",
            "loss: 1.849179  [  128/ 4708]\n",
            "loss: 1.848451  [  768/ 4708]\n",
            "loss: 1.853084  [ 1408/ 4708]\n",
            "loss: 1.838682  [ 2048/ 4708]\n",
            "loss: 1.844457  [ 2688/ 4708]\n",
            "loss: 1.858572  [ 3328/ 4708]\n",
            "loss: 1.856932  [ 3968/ 4708]\n",
            "loss: 1.851897  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 128\n",
            "-------------------------------\n",
            "loss: 1.836406  [  128/ 4708]\n",
            "loss: 1.848375  [  768/ 4708]\n",
            "loss: 1.866254  [ 1408/ 4708]\n",
            "loss: 1.863823  [ 2048/ 4708]\n",
            "loss: 1.842387  [ 2688/ 4708]\n",
            "loss: 1.848639  [ 3328/ 4708]\n",
            "loss: 1.865765  [ 3968/ 4708]\n",
            "loss: 1.865125  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 129\n",
            "-------------------------------\n",
            "loss: 1.833167  [  128/ 4708]\n",
            "loss: 1.857734  [  768/ 4708]\n",
            "loss: 1.841054  [ 1408/ 4708]\n",
            "loss: 1.875315  [ 2048/ 4708]\n",
            "loss: 1.822675  [ 2688/ 4708]\n",
            "loss: 1.871468  [ 3328/ 4708]\n",
            "loss: 1.863048  [ 3968/ 4708]\n",
            "loss: 1.839262  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 130\n",
            "-------------------------------\n",
            "loss: 1.865012  [  128/ 4708]\n",
            "loss: 1.822788  [  768/ 4708]\n",
            "loss: 1.836961  [ 1408/ 4708]\n",
            "loss: 1.823597  [ 2048/ 4708]\n",
            "loss: 1.862027  [ 2688/ 4708]\n",
            "loss: 1.853257  [ 3328/ 4708]\n",
            "loss: 1.827287  [ 3968/ 4708]\n",
            "loss: 1.871534  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 131\n",
            "-------------------------------\n",
            "loss: 1.862462  [  128/ 4708]\n",
            "loss: 1.826974  [  768/ 4708]\n",
            "loss: 1.849566  [ 1408/ 4708]\n",
            "loss: 1.848257  [ 2048/ 4708]\n",
            "loss: 1.869879  [ 2688/ 4708]\n",
            "loss: 1.842487  [ 3328/ 4708]\n",
            "loss: 1.855444  [ 3968/ 4708]\n",
            "loss: 1.865868  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 132\n",
            "-------------------------------\n",
            "loss: 1.855532  [  128/ 4708]\n",
            "loss: 1.868759  [  768/ 4708]\n",
            "loss: 1.839345  [ 1408/ 4708]\n",
            "loss: 1.848196  [ 2048/ 4708]\n",
            "loss: 1.862844  [ 2688/ 4708]\n",
            "loss: 1.844047  [ 3328/ 4708]\n",
            "loss: 1.830219  [ 3968/ 4708]\n",
            "loss: 1.846778  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 133\n",
            "-------------------------------\n",
            "loss: 1.856341  [  128/ 4708]\n",
            "loss: 1.855682  [  768/ 4708]\n",
            "loss: 1.809769  [ 1408/ 4708]\n",
            "loss: 1.867500  [ 2048/ 4708]\n",
            "loss: 1.872825  [ 2688/ 4708]\n",
            "loss: 1.845669  [ 3328/ 4708]\n",
            "loss: 1.847756  [ 3968/ 4708]\n",
            "loss: 1.835391  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 134\n",
            "-------------------------------\n",
            "loss: 1.876175  [  128/ 4708]\n",
            "loss: 1.836291  [  768/ 4708]\n",
            "loss: 1.858064  [ 1408/ 4708]\n",
            "loss: 1.850635  [ 2048/ 4708]\n",
            "loss: 1.798204  [ 2688/ 4708]\n",
            "loss: 1.864586  [ 3328/ 4708]\n",
            "loss: 1.863879  [ 3968/ 4708]\n",
            "loss: 1.853922  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 135\n",
            "-------------------------------\n",
            "loss: 1.858678  [  128/ 4708]\n",
            "loss: 1.848324  [  768/ 4708]\n",
            "loss: 1.840922  [ 1408/ 4708]\n",
            "loss: 1.843990  [ 2048/ 4708]\n",
            "loss: 1.820162  [ 2688/ 4708]\n",
            "loss: 1.855395  [ 3328/ 4708]\n",
            "loss: 1.868531  [ 3968/ 4708]\n",
            "loss: 1.855110  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 136\n",
            "-------------------------------\n",
            "loss: 1.839746  [  128/ 4708]\n",
            "loss: 1.872266  [  768/ 4708]\n",
            "loss: 1.886452  [ 1408/ 4708]\n",
            "loss: 1.827365  [ 2048/ 4708]\n",
            "loss: 1.863720  [ 2688/ 4708]\n",
            "loss: 1.831945  [ 3328/ 4708]\n",
            "loss: 1.839538  [ 3968/ 4708]\n",
            "loss: 1.861629  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 137\n",
            "-------------------------------\n",
            "loss: 1.875321  [  128/ 4708]\n",
            "loss: 1.825652  [  768/ 4708]\n",
            "loss: 1.831281  [ 1408/ 4708]\n",
            "loss: 1.852529  [ 2048/ 4708]\n",
            "loss: 1.834490  [ 2688/ 4708]\n",
            "loss: 1.880832  [ 3328/ 4708]\n",
            "loss: 1.842109  [ 3968/ 4708]\n",
            "loss: 1.855843  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 138\n",
            "-------------------------------\n",
            "loss: 1.864533  [  128/ 4708]\n",
            "loss: 1.863519  [  768/ 4708]\n",
            "loss: 1.858121  [ 1408/ 4708]\n",
            "loss: 1.850689  [ 2048/ 4708]\n",
            "loss: 1.848469  [ 2688/ 4708]\n",
            "loss: 1.871582  [ 3328/ 4708]\n",
            "loss: 1.826844  [ 3968/ 4708]\n",
            "loss: 1.874720  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 139\n",
            "-------------------------------\n",
            "loss: 1.851274  [  128/ 4708]\n",
            "loss: 1.840425  [  768/ 4708]\n",
            "loss: 1.848649  [ 1408/ 4708]\n",
            "loss: 1.851075  [ 2048/ 4708]\n",
            "loss: 1.845594  [ 2688/ 4708]\n",
            "loss: 1.850843  [ 3328/ 4708]\n",
            "loss: 1.839872  [ 3968/ 4708]\n",
            "loss: 1.877876  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 140\n",
            "-------------------------------\n",
            "loss: 1.876037  [  128/ 4708]\n",
            "loss: 1.847810  [  768/ 4708]\n",
            "loss: 1.838079  [ 1408/ 4708]\n",
            "loss: 1.850616  [ 2048/ 4708]\n",
            "loss: 1.831035  [ 2688/ 4708]\n",
            "loss: 1.829059  [ 3328/ 4708]\n",
            "loss: 1.871485  [ 3968/ 4708]\n",
            "loss: 1.880481  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 141\n",
            "-------------------------------\n",
            "loss: 1.835195  [  128/ 4708]\n",
            "loss: 1.835446  [  768/ 4708]\n",
            "loss: 1.871082  [ 1408/ 4708]\n",
            "loss: 1.848350  [ 2048/ 4708]\n",
            "loss: 1.836422  [ 2688/ 4708]\n",
            "loss: 1.850010  [ 3328/ 4708]\n",
            "loss: 1.840774  [ 3968/ 4708]\n",
            "loss: 1.861469  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 142\n",
            "-------------------------------\n",
            "loss: 1.871351  [  128/ 4708]\n",
            "loss: 1.852148  [  768/ 4708]\n",
            "loss: 1.869800  [ 1408/ 4708]\n",
            "loss: 1.843961  [ 2048/ 4708]\n",
            "loss: 1.855271  [ 2688/ 4708]\n",
            "loss: 1.842652  [ 3328/ 4708]\n",
            "loss: 1.841559  [ 3968/ 4708]\n",
            "loss: 1.858636  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 143\n",
            "-------------------------------\n",
            "loss: 1.847313  [  128/ 4708]\n",
            "loss: 1.838261  [  768/ 4708]\n",
            "loss: 1.855357  [ 1408/ 4708]\n",
            "loss: 1.832678  [ 2048/ 4708]\n",
            "loss: 1.834507  [ 2688/ 4708]\n",
            "loss: 1.890126  [ 3328/ 4708]\n",
            "loss: 1.836751  [ 3968/ 4708]\n",
            "loss: 1.845734  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 144\n",
            "-------------------------------\n",
            "loss: 1.833688  [  128/ 4708]\n",
            "loss: 1.877007  [  768/ 4708]\n",
            "loss: 1.856033  [ 1408/ 4708]\n",
            "loss: 1.856477  [ 2048/ 4708]\n",
            "loss: 1.852511  [ 2688/ 4708]\n",
            "loss: 1.881468  [ 3328/ 4708]\n",
            "loss: 1.860037  [ 3968/ 4708]\n",
            "loss: 1.841167  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 145\n",
            "-------------------------------\n",
            "loss: 1.853698  [  128/ 4708]\n",
            "loss: 1.868254  [  768/ 4708]\n",
            "loss: 1.881454  [ 1408/ 4708]\n",
            "loss: 1.821970  [ 2048/ 4708]\n",
            "loss: 1.828888  [ 2688/ 4708]\n",
            "loss: 1.857782  [ 3328/ 4708]\n",
            "loss: 1.860489  [ 3968/ 4708]\n",
            "loss: 1.855932  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 146\n",
            "-------------------------------\n",
            "loss: 1.799340  [  128/ 4708]\n",
            "loss: 1.854106  [  768/ 4708]\n",
            "loss: 1.849873  [ 1408/ 4708]\n",
            "loss: 1.834436  [ 2048/ 4708]\n",
            "loss: 1.862222  [ 2688/ 4708]\n",
            "loss: 1.846235  [ 3328/ 4708]\n",
            "loss: 1.867165  [ 3968/ 4708]\n",
            "loss: 1.861674  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 147\n",
            "-------------------------------\n",
            "loss: 1.848875  [  128/ 4708]\n",
            "loss: 1.850642  [  768/ 4708]\n",
            "loss: 1.871019  [ 1408/ 4708]\n",
            "loss: 1.853491  [ 2048/ 4708]\n",
            "loss: 1.856804  [ 2688/ 4708]\n",
            "loss: 1.854629  [ 3328/ 4708]\n",
            "loss: 1.839044  [ 3968/ 4708]\n",
            "loss: 1.876931  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 148\n",
            "-------------------------------\n",
            "loss: 1.873793  [  128/ 4708]\n",
            "loss: 1.830626  [  768/ 4708]\n",
            "loss: 1.836976  [ 1408/ 4708]\n",
            "loss: 1.866114  [ 2048/ 4708]\n",
            "loss: 1.852079  [ 2688/ 4708]\n",
            "loss: 1.843922  [ 3328/ 4708]\n",
            "loss: 1.855144  [ 3968/ 4708]\n",
            "loss: 1.837824  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 149\n",
            "-------------------------------\n",
            "loss: 1.852488  [  128/ 4708]\n",
            "loss: 1.829023  [  768/ 4708]\n",
            "loss: 1.869602  [ 1408/ 4708]\n",
            "loss: 1.811450  [ 2048/ 4708]\n",
            "loss: 1.818001  [ 2688/ 4708]\n",
            "loss: 1.873362  [ 3328/ 4708]\n",
            "loss: 1.824756  [ 3968/ 4708]\n",
            "loss: 1.850659  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 150\n",
            "-------------------------------\n",
            "loss: 1.875307  [  128/ 4708]\n",
            "loss: 1.864059  [  768/ 4708]\n",
            "loss: 1.817941  [ 1408/ 4708]\n",
            "loss: 1.876333  [ 2048/ 4708]\n",
            "loss: 1.852600  [ 2688/ 4708]\n",
            "loss: 1.841014  [ 3328/ 4708]\n",
            "loss: 1.847649  [ 3968/ 4708]\n",
            "loss: 1.857211  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 151\n",
            "-------------------------------\n",
            "loss: 1.863539  [  128/ 4708]\n",
            "loss: 1.865182  [  768/ 4708]\n",
            "loss: 1.856143  [ 1408/ 4708]\n",
            "loss: 1.849097  [ 2048/ 4708]\n",
            "loss: 1.852441  [ 2688/ 4708]\n",
            "loss: 1.861144  [ 3328/ 4708]\n",
            "loss: 1.828706  [ 3968/ 4708]\n",
            "loss: 1.867598  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 152\n",
            "-------------------------------\n",
            "loss: 1.822016  [  128/ 4708]\n",
            "loss: 1.861345  [  768/ 4708]\n",
            "loss: 1.844891  [ 1408/ 4708]\n",
            "loss: 1.862812  [ 2048/ 4708]\n",
            "loss: 1.831629  [ 2688/ 4708]\n",
            "loss: 1.849654  [ 3328/ 4708]\n",
            "loss: 1.839921  [ 3968/ 4708]\n",
            "loss: 1.845029  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 153\n",
            "-------------------------------\n",
            "loss: 1.865630  [  128/ 4708]\n",
            "loss: 1.857596  [  768/ 4708]\n",
            "loss: 1.826778  [ 1408/ 4708]\n",
            "loss: 1.850740  [ 2048/ 4708]\n",
            "loss: 1.841867  [ 2688/ 4708]\n",
            "loss: 1.844379  [ 3328/ 4708]\n",
            "loss: 1.837437  [ 3968/ 4708]\n",
            "loss: 1.859521  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 154\n",
            "-------------------------------\n",
            "loss: 1.855828  [  128/ 4708]\n",
            "loss: 1.837833  [  768/ 4708]\n",
            "loss: 1.837750  [ 1408/ 4708]\n",
            "loss: 1.830130  [ 2048/ 4708]\n",
            "loss: 1.871361  [ 2688/ 4708]\n",
            "loss: 1.829876  [ 3328/ 4708]\n",
            "loss: 1.864370  [ 3968/ 4708]\n",
            "loss: 1.859819  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 155\n",
            "-------------------------------\n",
            "loss: 1.840301  [  128/ 4708]\n",
            "loss: 1.824825  [  768/ 4708]\n",
            "loss: 1.860081  [ 1408/ 4708]\n",
            "loss: 1.864469  [ 2048/ 4708]\n",
            "loss: 1.825026  [ 2688/ 4708]\n",
            "loss: 1.849768  [ 3328/ 4708]\n",
            "loss: 1.843791  [ 3968/ 4708]\n",
            "loss: 1.880092  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 156\n",
            "-------------------------------\n",
            "loss: 1.854414  [  128/ 4708]\n",
            "loss: 1.831751  [  768/ 4708]\n",
            "loss: 1.851599  [ 1408/ 4708]\n",
            "loss: 1.871009  [ 2048/ 4708]\n",
            "loss: 1.845511  [ 2688/ 4708]\n",
            "loss: 1.836378  [ 3328/ 4708]\n",
            "loss: 1.848056  [ 3968/ 4708]\n",
            "loss: 1.854137  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 157\n",
            "-------------------------------\n",
            "loss: 1.848442  [  128/ 4708]\n",
            "loss: 1.863961  [  768/ 4708]\n",
            "loss: 1.813511  [ 1408/ 4708]\n",
            "loss: 1.846303  [ 2048/ 4708]\n",
            "loss: 1.859979  [ 2688/ 4708]\n",
            "loss: 1.860932  [ 3328/ 4708]\n",
            "loss: 1.847283  [ 3968/ 4708]\n",
            "loss: 1.853611  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 158\n",
            "-------------------------------\n",
            "loss: 1.832956  [  128/ 4708]\n",
            "loss: 1.843014  [  768/ 4708]\n",
            "loss: 1.841347  [ 1408/ 4708]\n",
            "loss: 1.852398  [ 2048/ 4708]\n",
            "loss: 1.816224  [ 2688/ 4708]\n",
            "loss: 1.847834  [ 3328/ 4708]\n",
            "loss: 1.839617  [ 3968/ 4708]\n",
            "loss: 1.840854  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 159\n",
            "-------------------------------\n",
            "loss: 1.826394  [  128/ 4708]\n",
            "loss: 1.857483  [  768/ 4708]\n",
            "loss: 1.835175  [ 1408/ 4708]\n",
            "loss: 1.850803  [ 2048/ 4708]\n",
            "loss: 1.861515  [ 2688/ 4708]\n",
            "loss: 1.859819  [ 3328/ 4708]\n",
            "loss: 1.849567  [ 3968/ 4708]\n",
            "loss: 1.840960  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 160\n",
            "-------------------------------\n",
            "loss: 1.812818  [  128/ 4708]\n",
            "loss: 1.875423  [  768/ 4708]\n",
            "loss: 1.847743  [ 1408/ 4708]\n",
            "loss: 1.835621  [ 2048/ 4708]\n",
            "loss: 1.874671  [ 2688/ 4708]\n",
            "loss: 1.861699  [ 3328/ 4708]\n",
            "loss: 1.832384  [ 3968/ 4708]\n",
            "loss: 1.838411  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 161\n",
            "-------------------------------\n",
            "loss: 1.842727  [  128/ 4708]\n",
            "loss: 1.851233  [  768/ 4708]\n",
            "loss: 1.856940  [ 1408/ 4708]\n",
            "loss: 1.848322  [ 2048/ 4708]\n",
            "loss: 1.868174  [ 2688/ 4708]\n",
            "loss: 1.860975  [ 3328/ 4708]\n",
            "loss: 1.849195  [ 3968/ 4708]\n",
            "loss: 1.881062  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 162\n",
            "-------------------------------\n",
            "loss: 1.841907  [  128/ 4708]\n",
            "loss: 1.815018  [  768/ 4708]\n",
            "loss: 1.864219  [ 1408/ 4708]\n",
            "loss: 1.862936  [ 2048/ 4708]\n",
            "loss: 1.839734  [ 2688/ 4708]\n",
            "loss: 1.838230  [ 3328/ 4708]\n",
            "loss: 1.848527  [ 3968/ 4708]\n",
            "loss: 1.836818  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 163\n",
            "-------------------------------\n",
            "loss: 1.878330  [  128/ 4708]\n",
            "loss: 1.838482  [  768/ 4708]\n",
            "loss: 1.850098  [ 1408/ 4708]\n",
            "loss: 1.873005  [ 2048/ 4708]\n",
            "loss: 1.811689  [ 2688/ 4708]\n",
            "loss: 1.842373  [ 3328/ 4708]\n",
            "loss: 1.847683  [ 3968/ 4708]\n",
            "loss: 1.862205  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 164\n",
            "-------------------------------\n",
            "loss: 1.861088  [  128/ 4708]\n",
            "loss: 1.848110  [  768/ 4708]\n",
            "loss: 1.829268  [ 1408/ 4708]\n",
            "loss: 1.870631  [ 2048/ 4708]\n",
            "loss: 1.847267  [ 2688/ 4708]\n",
            "loss: 1.845514  [ 3328/ 4708]\n",
            "loss: 1.827357  [ 3968/ 4708]\n",
            "loss: 1.873807  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 165\n",
            "-------------------------------\n",
            "loss: 1.844786  [  128/ 4708]\n",
            "loss: 1.842980  [  768/ 4708]\n",
            "loss: 1.851180  [ 1408/ 4708]\n",
            "loss: 1.837380  [ 2048/ 4708]\n",
            "loss: 1.866399  [ 2688/ 4708]\n",
            "loss: 1.836768  [ 3328/ 4708]\n",
            "loss: 1.877269  [ 3968/ 4708]\n",
            "loss: 1.835746  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 166\n",
            "-------------------------------\n",
            "loss: 1.845547  [  128/ 4708]\n",
            "loss: 1.850823  [  768/ 4708]\n",
            "loss: 1.844927  [ 1408/ 4708]\n",
            "loss: 1.859885  [ 2048/ 4708]\n",
            "loss: 1.849345  [ 2688/ 4708]\n",
            "loss: 1.830219  [ 3328/ 4708]\n",
            "loss: 1.853703  [ 3968/ 4708]\n",
            "loss: 1.855317  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 167\n",
            "-------------------------------\n",
            "loss: 1.851252  [  128/ 4708]\n",
            "loss: 1.865220  [  768/ 4708]\n",
            "loss: 1.817915  [ 1408/ 4708]\n",
            "loss: 1.832995  [ 2048/ 4708]\n",
            "loss: 1.857821  [ 2688/ 4708]\n",
            "loss: 1.854721  [ 3328/ 4708]\n",
            "loss: 1.838116  [ 3968/ 4708]\n",
            "loss: 1.874064  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 168\n",
            "-------------------------------\n",
            "loss: 1.835086  [  128/ 4708]\n",
            "loss: 1.858566  [  768/ 4708]\n",
            "loss: 1.859628  [ 1408/ 4708]\n",
            "loss: 1.828784  [ 2048/ 4708]\n",
            "loss: 1.863573  [ 2688/ 4708]\n",
            "loss: 1.862684  [ 3328/ 4708]\n",
            "loss: 1.874943  [ 3968/ 4708]\n",
            "loss: 1.850264  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 169\n",
            "-------------------------------\n",
            "loss: 1.838689  [  128/ 4708]\n",
            "loss: 1.853638  [  768/ 4708]\n",
            "loss: 1.812693  [ 1408/ 4708]\n",
            "loss: 1.852634  [ 2048/ 4708]\n",
            "loss: 1.875991  [ 2688/ 4708]\n",
            "loss: 1.844814  [ 3328/ 4708]\n",
            "loss: 1.850361  [ 3968/ 4708]\n",
            "loss: 1.868620  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 170\n",
            "-------------------------------\n",
            "loss: 1.835241  [  128/ 4708]\n",
            "loss: 1.846214  [  768/ 4708]\n",
            "loss: 1.870495  [ 1408/ 4708]\n",
            "loss: 1.865251  [ 2048/ 4708]\n",
            "loss: 1.884124  [ 2688/ 4708]\n",
            "loss: 1.824015  [ 3328/ 4708]\n",
            "loss: 1.871357  [ 3968/ 4708]\n",
            "loss: 1.848244  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 171\n",
            "-------------------------------\n",
            "loss: 1.876989  [  128/ 4708]\n",
            "loss: 1.865613  [  768/ 4708]\n",
            "loss: 1.851114  [ 1408/ 4708]\n",
            "loss: 1.848265  [ 2048/ 4708]\n",
            "loss: 1.863202  [ 2688/ 4708]\n",
            "loss: 1.852195  [ 3328/ 4708]\n",
            "loss: 1.821523  [ 3968/ 4708]\n",
            "loss: 1.855043  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 172\n",
            "-------------------------------\n",
            "loss: 1.852098  [  128/ 4708]\n",
            "loss: 1.867884  [  768/ 4708]\n",
            "loss: 1.835801  [ 1408/ 4708]\n",
            "loss: 1.845935  [ 2048/ 4708]\n",
            "loss: 1.854082  [ 2688/ 4708]\n",
            "loss: 1.842772  [ 3328/ 4708]\n",
            "loss: 1.857221  [ 3968/ 4708]\n",
            "loss: 1.874469  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 173\n",
            "-------------------------------\n",
            "loss: 1.844612  [  128/ 4708]\n",
            "loss: 1.856403  [  768/ 4708]\n",
            "loss: 1.863959  [ 1408/ 4708]\n",
            "loss: 1.858697  [ 2048/ 4708]\n",
            "loss: 1.854968  [ 2688/ 4708]\n",
            "loss: 1.886487  [ 3328/ 4708]\n",
            "loss: 1.836946  [ 3968/ 4708]\n",
            "loss: 1.861643  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 174\n",
            "-------------------------------\n",
            "loss: 1.864336  [  128/ 4708]\n",
            "loss: 1.847327  [  768/ 4708]\n",
            "loss: 1.866741  [ 1408/ 4708]\n",
            "loss: 1.811908  [ 2048/ 4708]\n",
            "loss: 1.854841  [ 2688/ 4708]\n",
            "loss: 1.868223  [ 3328/ 4708]\n",
            "loss: 1.828960  [ 3968/ 4708]\n",
            "loss: 1.841457  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 175\n",
            "-------------------------------\n",
            "loss: 1.825383  [  128/ 4708]\n",
            "loss: 1.860008  [  768/ 4708]\n",
            "loss: 1.854267  [ 1408/ 4708]\n",
            "loss: 1.851665  [ 2048/ 4708]\n",
            "loss: 1.842020  [ 2688/ 4708]\n",
            "loss: 1.884636  [ 3328/ 4708]\n",
            "loss: 1.832882  [ 3968/ 4708]\n",
            "loss: 1.872054  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 176\n",
            "-------------------------------\n",
            "loss: 1.853752  [  128/ 4708]\n",
            "loss: 1.843843  [  768/ 4708]\n",
            "loss: 1.828815  [ 1408/ 4708]\n",
            "loss: 1.866253  [ 2048/ 4708]\n",
            "loss: 1.865331  [ 2688/ 4708]\n",
            "loss: 1.841053  [ 3328/ 4708]\n",
            "loss: 1.845507  [ 3968/ 4708]\n",
            "loss: 1.861868  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 177\n",
            "-------------------------------\n",
            "loss: 1.856677  [  128/ 4708]\n",
            "loss: 1.863674  [  768/ 4708]\n",
            "loss: 1.867957  [ 1408/ 4708]\n",
            "loss: 1.839901  [ 2048/ 4708]\n",
            "loss: 1.834918  [ 2688/ 4708]\n",
            "loss: 1.867348  [ 3328/ 4708]\n",
            "loss: 1.859011  [ 3968/ 4708]\n",
            "loss: 1.869740  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 178\n",
            "-------------------------------\n",
            "loss: 1.811929  [  128/ 4708]\n",
            "loss: 1.821059  [  768/ 4708]\n",
            "loss: 1.864738  [ 1408/ 4708]\n",
            "loss: 1.842218  [ 2048/ 4708]\n",
            "loss: 1.876139  [ 2688/ 4708]\n",
            "loss: 1.828134  [ 3328/ 4708]\n",
            "loss: 1.839514  [ 3968/ 4708]\n",
            "loss: 1.856171  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 179\n",
            "-------------------------------\n",
            "loss: 1.837024  [  128/ 4708]\n",
            "loss: 1.869561  [  768/ 4708]\n",
            "loss: 1.864445  [ 1408/ 4708]\n",
            "loss: 1.857922  [ 2048/ 4708]\n",
            "loss: 1.857040  [ 2688/ 4708]\n",
            "loss: 1.818472  [ 3328/ 4708]\n",
            "loss: 1.868924  [ 3968/ 4708]\n",
            "loss: 1.824819  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 180\n",
            "-------------------------------\n",
            "loss: 1.852533  [  128/ 4708]\n",
            "loss: 1.858953  [  768/ 4708]\n",
            "loss: 1.822423  [ 1408/ 4708]\n",
            "loss: 1.863136  [ 2048/ 4708]\n",
            "loss: 1.833306  [ 2688/ 4708]\n",
            "loss: 1.858380  [ 3328/ 4708]\n",
            "loss: 1.830523  [ 3968/ 4708]\n",
            "loss: 1.854085  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 181\n",
            "-------------------------------\n",
            "loss: 1.845169  [  128/ 4708]\n",
            "loss: 1.827733  [  768/ 4708]\n",
            "loss: 1.858267  [ 1408/ 4708]\n",
            "loss: 1.829867  [ 2048/ 4708]\n",
            "loss: 1.842722  [ 2688/ 4708]\n",
            "loss: 1.854539  [ 3328/ 4708]\n",
            "loss: 1.842165  [ 3968/ 4708]\n",
            "loss: 1.849004  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 182\n",
            "-------------------------------\n",
            "loss: 1.833442  [  128/ 4708]\n",
            "loss: 1.868870  [  768/ 4708]\n",
            "loss: 1.877017  [ 1408/ 4708]\n",
            "loss: 1.870749  [ 2048/ 4708]\n",
            "loss: 1.876656  [ 2688/ 4708]\n",
            "loss: 1.839925  [ 3328/ 4708]\n",
            "loss: 1.858949  [ 3968/ 4708]\n",
            "loss: 1.849602  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 183\n",
            "-------------------------------\n",
            "loss: 1.854278  [  128/ 4708]\n",
            "loss: 1.847667  [  768/ 4708]\n",
            "loss: 1.855587  [ 1408/ 4708]\n",
            "loss: 1.851763  [ 2048/ 4708]\n",
            "loss: 1.854757  [ 2688/ 4708]\n",
            "loss: 1.855142  [ 3328/ 4708]\n",
            "loss: 1.859766  [ 3968/ 4708]\n",
            "loss: 1.797955  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 184\n",
            "-------------------------------\n",
            "loss: 1.839327  [  128/ 4708]\n",
            "loss: 1.857246  [  768/ 4708]\n",
            "loss: 1.871773  [ 1408/ 4708]\n",
            "loss: 1.855415  [ 2048/ 4708]\n",
            "loss: 1.863659  [ 2688/ 4708]\n",
            "loss: 1.858190  [ 3328/ 4708]\n",
            "loss: 1.869443  [ 3968/ 4708]\n",
            "loss: 1.839999  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 185\n",
            "-------------------------------\n",
            "loss: 1.842971  [  128/ 4708]\n",
            "loss: 1.832530  [  768/ 4708]\n",
            "loss: 1.844618  [ 1408/ 4708]\n",
            "loss: 1.829463  [ 2048/ 4708]\n",
            "loss: 1.840548  [ 2688/ 4708]\n",
            "loss: 1.860652  [ 3328/ 4708]\n",
            "loss: 1.824746  [ 3968/ 4708]\n",
            "loss: 1.844260  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 186\n",
            "-------------------------------\n",
            "loss: 1.859359  [  128/ 4708]\n",
            "loss: 1.852024  [  768/ 4708]\n",
            "loss: 1.834657  [ 1408/ 4708]\n",
            "loss: 1.817789  [ 2048/ 4708]\n",
            "loss: 1.871758  [ 2688/ 4708]\n",
            "loss: 1.831880  [ 3328/ 4708]\n",
            "loss: 1.839854  [ 3968/ 4708]\n",
            "loss: 1.885124  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 187\n",
            "-------------------------------\n",
            "loss: 1.873343  [  128/ 4708]\n",
            "loss: 1.829441  [  768/ 4708]\n",
            "loss: 1.857552  [ 1408/ 4708]\n",
            "loss: 1.838759  [ 2048/ 4708]\n",
            "loss: 1.837510  [ 2688/ 4708]\n",
            "loss: 1.845013  [ 3328/ 4708]\n",
            "loss: 1.852851  [ 3968/ 4708]\n",
            "loss: 1.846317  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 188\n",
            "-------------------------------\n",
            "loss: 1.851122  [  128/ 4708]\n",
            "loss: 1.847124  [  768/ 4708]\n",
            "loss: 1.838953  [ 1408/ 4708]\n",
            "loss: 1.844738  [ 2048/ 4708]\n",
            "loss: 1.831327  [ 2688/ 4708]\n",
            "loss: 1.879772  [ 3328/ 4708]\n",
            "loss: 1.853995  [ 3968/ 4708]\n",
            "loss: 1.843419  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 189\n",
            "-------------------------------\n",
            "loss: 1.826217  [  128/ 4708]\n",
            "loss: 1.866511  [  768/ 4708]\n",
            "loss: 1.848908  [ 1408/ 4708]\n",
            "loss: 1.847535  [ 2048/ 4708]\n",
            "loss: 1.843883  [ 2688/ 4708]\n",
            "loss: 1.852180  [ 3328/ 4708]\n",
            "loss: 1.852604  [ 3968/ 4708]\n",
            "loss: 1.843179  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 190\n",
            "-------------------------------\n",
            "loss: 1.863476  [  128/ 4708]\n",
            "loss: 1.877454  [  768/ 4708]\n",
            "loss: 1.858848  [ 1408/ 4708]\n",
            "loss: 1.849614  [ 2048/ 4708]\n",
            "loss: 1.853507  [ 2688/ 4708]\n",
            "loss: 1.859742  [ 3328/ 4708]\n",
            "loss: 1.844938  [ 3968/ 4708]\n",
            "loss: 1.840586  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 191\n",
            "-------------------------------\n",
            "loss: 1.861450  [  128/ 4708]\n",
            "loss: 1.829398  [  768/ 4708]\n",
            "loss: 1.856187  [ 1408/ 4708]\n",
            "loss: 1.857694  [ 2048/ 4708]\n",
            "loss: 1.846873  [ 2688/ 4708]\n",
            "loss: 1.828040  [ 3328/ 4708]\n",
            "loss: 1.849366  [ 3968/ 4708]\n",
            "loss: 1.850502  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 192\n",
            "-------------------------------\n",
            "loss: 1.838058  [  128/ 4708]\n",
            "loss: 1.849453  [  768/ 4708]\n",
            "loss: 1.864411  [ 1408/ 4708]\n",
            "loss: 1.859516  [ 2048/ 4708]\n",
            "loss: 1.873808  [ 2688/ 4708]\n",
            "loss: 1.859591  [ 3328/ 4708]\n",
            "loss: 1.847046  [ 3968/ 4708]\n",
            "loss: 1.835286  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 193\n",
            "-------------------------------\n",
            "loss: 1.848046  [  128/ 4708]\n",
            "loss: 1.842920  [  768/ 4708]\n",
            "loss: 1.853546  [ 1408/ 4708]\n",
            "loss: 1.851043  [ 2048/ 4708]\n",
            "loss: 1.827176  [ 2688/ 4708]\n",
            "loss: 1.827862  [ 3328/ 4708]\n",
            "loss: 1.872280  [ 3968/ 4708]\n",
            "loss: 1.859151  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 194\n",
            "-------------------------------\n",
            "loss: 1.859716  [  128/ 4708]\n",
            "loss: 1.859337  [  768/ 4708]\n",
            "loss: 1.849674  [ 1408/ 4708]\n",
            "loss: 1.870508  [ 2048/ 4708]\n",
            "loss: 1.874996  [ 2688/ 4708]\n",
            "loss: 1.859364  [ 3328/ 4708]\n",
            "loss: 1.847959  [ 3968/ 4708]\n",
            "loss: 1.846976  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 195\n",
            "-------------------------------\n",
            "loss: 1.879161  [  128/ 4708]\n",
            "loss: 1.848073  [  768/ 4708]\n",
            "loss: 1.859397  [ 1408/ 4708]\n",
            "loss: 1.856455  [ 2048/ 4708]\n",
            "loss: 1.843448  [ 2688/ 4708]\n",
            "loss: 1.850778  [ 3328/ 4708]\n",
            "loss: 1.883433  [ 3968/ 4708]\n",
            "loss: 1.879574  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 196\n",
            "-------------------------------\n",
            "loss: 1.834043  [  128/ 4708]\n",
            "loss: 1.831908  [  768/ 4708]\n",
            "loss: 1.853045  [ 1408/ 4708]\n",
            "loss: 1.854112  [ 2048/ 4708]\n",
            "loss: 1.851352  [ 2688/ 4708]\n",
            "loss: 1.844130  [ 3328/ 4708]\n",
            "loss: 1.838130  [ 3968/ 4708]\n",
            "loss: 1.836183  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 197\n",
            "-------------------------------\n",
            "loss: 1.859177  [  128/ 4708]\n",
            "loss: 1.828398  [  768/ 4708]\n",
            "loss: 1.866952  [ 1408/ 4708]\n",
            "loss: 1.854928  [ 2048/ 4708]\n",
            "loss: 1.818071  [ 2688/ 4708]\n",
            "loss: 1.847280  [ 3328/ 4708]\n",
            "loss: 1.861517  [ 3968/ 4708]\n",
            "loss: 1.860282  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 198\n",
            "-------------------------------\n",
            "loss: 1.843047  [  128/ 4708]\n",
            "loss: 1.836578  [  768/ 4708]\n",
            "loss: 1.866612  [ 1408/ 4708]\n",
            "loss: 1.853252  [ 2048/ 4708]\n",
            "loss: 1.879105  [ 2688/ 4708]\n",
            "loss: 1.836502  [ 3328/ 4708]\n",
            "loss: 1.856959  [ 3968/ 4708]\n",
            "loss: 1.833546  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 199\n",
            "-------------------------------\n",
            "loss: 1.861429  [  128/ 4708]\n",
            "loss: 1.870052  [  768/ 4708]\n",
            "loss: 1.861855  [ 1408/ 4708]\n",
            "loss: 1.862228  [ 2048/ 4708]\n",
            "loss: 1.853934  [ 2688/ 4708]\n",
            "loss: 1.827347  [ 3328/ 4708]\n",
            "loss: 1.813388  [ 3968/ 4708]\n",
            "loss: 1.843778  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 200\n",
            "-------------------------------\n",
            "loss: 1.869397  [  128/ 4708]\n",
            "loss: 1.833204  [  768/ 4708]\n",
            "loss: 1.860869  [ 1408/ 4708]\n",
            "loss: 1.848320  [ 2048/ 4708]\n",
            "loss: 1.846684  [ 2688/ 4708]\n",
            "loss: 1.844425  [ 3328/ 4708]\n",
            "loss: 1.859836  [ 3968/ 4708]\n",
            "loss: 1.834170  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 201\n",
            "-------------------------------\n",
            "loss: 1.843193  [  128/ 4708]\n",
            "loss: 1.869658  [  768/ 4708]\n",
            "loss: 1.849124  [ 1408/ 4708]\n",
            "loss: 1.859701  [ 2048/ 4708]\n",
            "loss: 1.862709  [ 2688/ 4708]\n",
            "loss: 1.843788  [ 3328/ 4708]\n",
            "loss: 1.844221  [ 3968/ 4708]\n",
            "loss: 1.847809  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 202\n",
            "-------------------------------\n",
            "loss: 1.863419  [  128/ 4708]\n",
            "loss: 1.883251  [  768/ 4708]\n",
            "loss: 1.837148  [ 1408/ 4708]\n",
            "loss: 1.850872  [ 2048/ 4708]\n",
            "loss: 1.822839  [ 2688/ 4708]\n",
            "loss: 1.824737  [ 3328/ 4708]\n",
            "loss: 1.870259  [ 3968/ 4708]\n",
            "loss: 1.837171  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 203\n",
            "-------------------------------\n",
            "loss: 1.838028  [  128/ 4708]\n",
            "loss: 1.837856  [  768/ 4708]\n",
            "loss: 1.861488  [ 1408/ 4708]\n",
            "loss: 1.850456  [ 2048/ 4708]\n",
            "loss: 1.822872  [ 2688/ 4708]\n",
            "loss: 1.864386  [ 3328/ 4708]\n",
            "loss: 1.851425  [ 3968/ 4708]\n",
            "loss: 1.818785  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 204\n",
            "-------------------------------\n",
            "loss: 1.840875  [  128/ 4708]\n",
            "loss: 1.857973  [  768/ 4708]\n",
            "loss: 1.860614  [ 1408/ 4708]\n",
            "loss: 1.849795  [ 2048/ 4708]\n",
            "loss: 1.822635  [ 2688/ 4708]\n",
            "loss: 1.885130  [ 3328/ 4708]\n",
            "loss: 1.861884  [ 3968/ 4708]\n",
            "loss: 1.843083  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 205\n",
            "-------------------------------\n",
            "loss: 1.843954  [  128/ 4708]\n",
            "loss: 1.830806  [  768/ 4708]\n",
            "loss: 1.823078  [ 1408/ 4708]\n",
            "loss: 1.863341  [ 2048/ 4708]\n",
            "loss: 1.866950  [ 2688/ 4708]\n",
            "loss: 1.869119  [ 3328/ 4708]\n",
            "loss: 1.838635  [ 3968/ 4708]\n",
            "loss: 1.865738  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 206\n",
            "-------------------------------\n",
            "loss: 1.871056  [  128/ 4708]\n",
            "loss: 1.844779  [  768/ 4708]\n",
            "loss: 1.830055  [ 1408/ 4708]\n",
            "loss: 1.830192  [ 2048/ 4708]\n",
            "loss: 1.844411  [ 2688/ 4708]\n",
            "loss: 1.847368  [ 3328/ 4708]\n",
            "loss: 1.861268  [ 3968/ 4708]\n",
            "loss: 1.829674  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 207\n",
            "-------------------------------\n",
            "loss: 1.843962  [  128/ 4708]\n",
            "loss: 1.856481  [  768/ 4708]\n",
            "loss: 1.873448  [ 1408/ 4708]\n",
            "loss: 1.854964  [ 2048/ 4708]\n",
            "loss: 1.873863  [ 2688/ 4708]\n",
            "loss: 1.844148  [ 3328/ 4708]\n",
            "loss: 1.825730  [ 3968/ 4708]\n",
            "loss: 1.865861  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 208\n",
            "-------------------------------\n",
            "loss: 1.848789  [  128/ 4708]\n",
            "loss: 1.860892  [  768/ 4708]\n",
            "loss: 1.857626  [ 1408/ 4708]\n",
            "loss: 1.880643  [ 2048/ 4708]\n",
            "loss: 1.868616  [ 2688/ 4708]\n",
            "loss: 1.792851  [ 3328/ 4708]\n",
            "loss: 1.846207  [ 3968/ 4708]\n",
            "loss: 1.858018  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 209\n",
            "-------------------------------\n",
            "loss: 1.845711  [  128/ 4708]\n",
            "loss: 1.843093  [  768/ 4708]\n",
            "loss: 1.831900  [ 1408/ 4708]\n",
            "loss: 1.852367  [ 2048/ 4708]\n",
            "loss: 1.873371  [ 2688/ 4708]\n",
            "loss: 1.845500  [ 3328/ 4708]\n",
            "loss: 1.860448  [ 3968/ 4708]\n",
            "loss: 1.856110  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 210\n",
            "-------------------------------\n",
            "loss: 1.860006  [  128/ 4708]\n",
            "loss: 1.865372  [  768/ 4708]\n",
            "loss: 1.856659  [ 1408/ 4708]\n",
            "loss: 1.891393  [ 2048/ 4708]\n",
            "loss: 1.817325  [ 2688/ 4708]\n",
            "loss: 1.876438  [ 3328/ 4708]\n",
            "loss: 1.854247  [ 3968/ 4708]\n",
            "loss: 1.842620  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 211\n",
            "-------------------------------\n",
            "loss: 1.861088  [  128/ 4708]\n",
            "loss: 1.843270  [  768/ 4708]\n",
            "loss: 1.857953  [ 1408/ 4708]\n",
            "loss: 1.834760  [ 2048/ 4708]\n",
            "loss: 1.830046  [ 2688/ 4708]\n",
            "loss: 1.840824  [ 3328/ 4708]\n",
            "loss: 1.864115  [ 3968/ 4708]\n",
            "loss: 1.829914  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 212\n",
            "-------------------------------\n",
            "loss: 1.854763  [  128/ 4708]\n",
            "loss: 1.864143  [  768/ 4708]\n",
            "loss: 1.851343  [ 1408/ 4708]\n",
            "loss: 1.849213  [ 2048/ 4708]\n",
            "loss: 1.853961  [ 2688/ 4708]\n",
            "loss: 1.841302  [ 3328/ 4708]\n",
            "loss: 1.828992  [ 3968/ 4708]\n",
            "loss: 1.877606  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 213\n",
            "-------------------------------\n",
            "loss: 1.840084  [  128/ 4708]\n",
            "loss: 1.845293  [  768/ 4708]\n",
            "loss: 1.833408  [ 1408/ 4708]\n",
            "loss: 1.865736  [ 2048/ 4708]\n",
            "loss: 1.861351  [ 2688/ 4708]\n",
            "loss: 1.854816  [ 3328/ 4708]\n",
            "loss: 1.844127  [ 3968/ 4708]\n",
            "loss: 1.818552  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 214\n",
            "-------------------------------\n",
            "loss: 1.827356  [  128/ 4708]\n",
            "loss: 1.839317  [  768/ 4708]\n",
            "loss: 1.827865  [ 1408/ 4708]\n",
            "loss: 1.856365  [ 2048/ 4708]\n",
            "loss: 1.860109  [ 2688/ 4708]\n",
            "loss: 1.843230  [ 3328/ 4708]\n",
            "loss: 1.873188  [ 3968/ 4708]\n",
            "loss: 1.847052  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 215\n",
            "-------------------------------\n",
            "loss: 1.862496  [  128/ 4708]\n",
            "loss: 1.841524  [  768/ 4708]\n",
            "loss: 1.859475  [ 1408/ 4708]\n",
            "loss: 1.831757  [ 2048/ 4708]\n",
            "loss: 1.852020  [ 2688/ 4708]\n",
            "loss: 1.850381  [ 3328/ 4708]\n",
            "loss: 1.866718  [ 3968/ 4708]\n",
            "loss: 1.845704  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 216\n",
            "-------------------------------\n",
            "loss: 1.844624  [  128/ 4708]\n",
            "loss: 1.856562  [  768/ 4708]\n",
            "loss: 1.846631  [ 1408/ 4708]\n",
            "loss: 1.874061  [ 2048/ 4708]\n",
            "loss: 1.872418  [ 2688/ 4708]\n",
            "loss: 1.826260  [ 3328/ 4708]\n",
            "loss: 1.837624  [ 3968/ 4708]\n",
            "loss: 1.854352  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 217\n",
            "-------------------------------\n",
            "loss: 1.854105  [  128/ 4708]\n",
            "loss: 1.872112  [  768/ 4708]\n",
            "loss: 1.836251  [ 1408/ 4708]\n",
            "loss: 1.856783  [ 2048/ 4708]\n",
            "loss: 1.839288  [ 2688/ 4708]\n",
            "loss: 1.866728  [ 3328/ 4708]\n",
            "loss: 1.819430  [ 3968/ 4708]\n",
            "loss: 1.854373  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 218\n",
            "-------------------------------\n",
            "loss: 1.893907  [  128/ 4708]\n",
            "loss: 1.861476  [  768/ 4708]\n",
            "loss: 1.845751  [ 1408/ 4708]\n",
            "loss: 1.895794  [ 2048/ 4708]\n",
            "loss: 1.841516  [ 2688/ 4708]\n",
            "loss: 1.837685  [ 3328/ 4708]\n",
            "loss: 1.868304  [ 3968/ 4708]\n",
            "loss: 1.855679  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 219\n",
            "-------------------------------\n",
            "loss: 1.874113  [  128/ 4708]\n",
            "loss: 1.825334  [  768/ 4708]\n",
            "loss: 1.801718  [ 1408/ 4708]\n",
            "loss: 1.852026  [ 2048/ 4708]\n",
            "loss: 1.867760  [ 2688/ 4708]\n",
            "loss: 1.843710  [ 3328/ 4708]\n",
            "loss: 1.837258  [ 3968/ 4708]\n",
            "loss: 1.826204  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 220\n",
            "-------------------------------\n",
            "loss: 1.830868  [  128/ 4708]\n",
            "loss: 1.834853  [  768/ 4708]\n",
            "loss: 1.868461  [ 1408/ 4708]\n",
            "loss: 1.849628  [ 2048/ 4708]\n",
            "loss: 1.888211  [ 2688/ 4708]\n",
            "loss: 1.861061  [ 3328/ 4708]\n",
            "loss: 1.865729  [ 3968/ 4708]\n",
            "loss: 1.841302  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 221\n",
            "-------------------------------\n",
            "loss: 1.830057  [  128/ 4708]\n",
            "loss: 1.845052  [  768/ 4708]\n",
            "loss: 1.850943  [ 1408/ 4708]\n",
            "loss: 1.826157  [ 2048/ 4708]\n",
            "loss: 1.844392  [ 2688/ 4708]\n",
            "loss: 1.863470  [ 3328/ 4708]\n",
            "loss: 1.855330  [ 3968/ 4708]\n",
            "loss: 1.865765  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 222\n",
            "-------------------------------\n",
            "loss: 1.855039  [  128/ 4708]\n",
            "loss: 1.845056  [  768/ 4708]\n",
            "loss: 1.845705  [ 1408/ 4708]\n",
            "loss: 1.846322  [ 2048/ 4708]\n",
            "loss: 1.866162  [ 2688/ 4708]\n",
            "loss: 1.847218  [ 3328/ 4708]\n",
            "loss: 1.828818  [ 3968/ 4708]\n",
            "loss: 1.881064  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 223\n",
            "-------------------------------\n",
            "loss: 1.844390  [  128/ 4708]\n",
            "loss: 1.854350  [  768/ 4708]\n",
            "loss: 1.833160  [ 1408/ 4708]\n",
            "loss: 1.833210  [ 2048/ 4708]\n",
            "loss: 1.862002  [ 2688/ 4708]\n",
            "loss: 1.820590  [ 3328/ 4708]\n",
            "loss: 1.862978  [ 3968/ 4708]\n",
            "loss: 1.859245  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 224\n",
            "-------------------------------\n",
            "loss: 1.826986  [  128/ 4708]\n",
            "loss: 1.862148  [  768/ 4708]\n",
            "loss: 1.840787  [ 1408/ 4708]\n",
            "loss: 1.854218  [ 2048/ 4708]\n",
            "loss: 1.877508  [ 2688/ 4708]\n",
            "loss: 1.849555  [ 3328/ 4708]\n",
            "loss: 1.845121  [ 3968/ 4708]\n",
            "loss: 1.863169  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 225\n",
            "-------------------------------\n",
            "loss: 1.846584  [  128/ 4708]\n",
            "loss: 1.843323  [  768/ 4708]\n",
            "loss: 1.826954  [ 1408/ 4708]\n",
            "loss: 1.853821  [ 2048/ 4708]\n",
            "loss: 1.848532  [ 2688/ 4708]\n",
            "loss: 1.841811  [ 3328/ 4708]\n",
            "loss: 1.850811  [ 3968/ 4708]\n",
            "loss: 1.830913  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 226\n",
            "-------------------------------\n",
            "loss: 1.858286  [  128/ 4708]\n",
            "loss: 1.850966  [  768/ 4708]\n",
            "loss: 1.840452  [ 1408/ 4708]\n",
            "loss: 1.813365  [ 2048/ 4708]\n",
            "loss: 1.845996  [ 2688/ 4708]\n",
            "loss: 1.834477  [ 3328/ 4708]\n",
            "loss: 1.851468  [ 3968/ 4708]\n",
            "loss: 1.854136  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 227\n",
            "-------------------------------\n",
            "loss: 1.878923  [  128/ 4708]\n",
            "loss: 1.845537  [  768/ 4708]\n",
            "loss: 1.846566  [ 1408/ 4708]\n",
            "loss: 1.830282  [ 2048/ 4708]\n",
            "loss: 1.866410  [ 2688/ 4708]\n",
            "loss: 1.871529  [ 3328/ 4708]\n",
            "loss: 1.849710  [ 3968/ 4708]\n",
            "loss: 1.822472  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 228\n",
            "-------------------------------\n",
            "loss: 1.862782  [  128/ 4708]\n",
            "loss: 1.867644  [  768/ 4708]\n",
            "loss: 1.859633  [ 1408/ 4708]\n",
            "loss: 1.836351  [ 2048/ 4708]\n",
            "loss: 1.864667  [ 2688/ 4708]\n",
            "loss: 1.835099  [ 3328/ 4708]\n",
            "loss: 1.836105  [ 3968/ 4708]\n",
            "loss: 1.813148  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 229\n",
            "-------------------------------\n",
            "loss: 1.850709  [  128/ 4708]\n",
            "loss: 1.852835  [  768/ 4708]\n",
            "loss: 1.841513  [ 1408/ 4708]\n",
            "loss: 1.865942  [ 2048/ 4708]\n",
            "loss: 1.801646  [ 2688/ 4708]\n",
            "loss: 1.838812  [ 3328/ 4708]\n",
            "loss: 1.835404  [ 3968/ 4708]\n",
            "loss: 1.847680  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 230\n",
            "-------------------------------\n",
            "loss: 1.841183  [  128/ 4708]\n",
            "loss: 1.862625  [  768/ 4708]\n",
            "loss: 1.852224  [ 1408/ 4708]\n",
            "loss: 1.838008  [ 2048/ 4708]\n",
            "loss: 1.843914  [ 2688/ 4708]\n",
            "loss: 1.874588  [ 3328/ 4708]\n",
            "loss: 1.845756  [ 3968/ 4708]\n",
            "loss: 1.867576  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 231\n",
            "-------------------------------\n",
            "loss: 1.857840  [  128/ 4708]\n",
            "loss: 1.869329  [  768/ 4708]\n",
            "loss: 1.853248  [ 1408/ 4708]\n",
            "loss: 1.856664  [ 2048/ 4708]\n",
            "loss: 1.851798  [ 2688/ 4708]\n",
            "loss: 1.840479  [ 3328/ 4708]\n",
            "loss: 1.841522  [ 3968/ 4708]\n",
            "loss: 1.844801  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 232\n",
            "-------------------------------\n",
            "loss: 1.875977  [  128/ 4708]\n",
            "loss: 1.863370  [  768/ 4708]\n",
            "loss: 1.840989  [ 1408/ 4708]\n",
            "loss: 1.854784  [ 2048/ 4708]\n",
            "loss: 1.848848  [ 2688/ 4708]\n",
            "loss: 1.849838  [ 3328/ 4708]\n",
            "loss: 1.845088  [ 3968/ 4708]\n",
            "loss: 1.838823  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 233\n",
            "-------------------------------\n",
            "loss: 1.803901  [  128/ 4708]\n",
            "loss: 1.881693  [  768/ 4708]\n",
            "loss: 1.836061  [ 1408/ 4708]\n",
            "loss: 1.842598  [ 2048/ 4708]\n",
            "loss: 1.841688  [ 2688/ 4708]\n",
            "loss: 1.856856  [ 3328/ 4708]\n",
            "loss: 1.858908  [ 3968/ 4708]\n",
            "loss: 1.828853  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 234\n",
            "-------------------------------\n",
            "loss: 1.875199  [  128/ 4708]\n",
            "loss: 1.824563  [  768/ 4708]\n",
            "loss: 1.816023  [ 1408/ 4708]\n",
            "loss: 1.863574  [ 2048/ 4708]\n",
            "loss: 1.841316  [ 2688/ 4708]\n",
            "loss: 1.833179  [ 3328/ 4708]\n",
            "loss: 1.851615  [ 3968/ 4708]\n",
            "loss: 1.853275  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 235\n",
            "-------------------------------\n",
            "loss: 1.840661  [  128/ 4708]\n",
            "loss: 1.861813  [  768/ 4708]\n",
            "loss: 1.849398  [ 1408/ 4708]\n",
            "loss: 1.840757  [ 2048/ 4708]\n",
            "loss: 1.876909  [ 2688/ 4708]\n",
            "loss: 1.845222  [ 3328/ 4708]\n",
            "loss: 1.856516  [ 3968/ 4708]\n",
            "loss: 1.841722  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 236\n",
            "-------------------------------\n",
            "loss: 1.851131  [  128/ 4708]\n",
            "loss: 1.859479  [  768/ 4708]\n",
            "loss: 1.835716  [ 1408/ 4708]\n",
            "loss: 1.828583  [ 2048/ 4708]\n",
            "loss: 1.848804  [ 2688/ 4708]\n",
            "loss: 1.871754  [ 3328/ 4708]\n",
            "loss: 1.862566  [ 3968/ 4708]\n",
            "loss: 1.830640  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 237\n",
            "-------------------------------\n",
            "loss: 1.851485  [  128/ 4708]\n",
            "loss: 1.847272  [  768/ 4708]\n",
            "loss: 1.839740  [ 1408/ 4708]\n",
            "loss: 1.831036  [ 2048/ 4708]\n",
            "loss: 1.805449  [ 2688/ 4708]\n",
            "loss: 1.872887  [ 3328/ 4708]\n",
            "loss: 1.900837  [ 3968/ 4708]\n",
            "loss: 1.853678  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 238\n",
            "-------------------------------\n",
            "loss: 1.874051  [  128/ 4708]\n",
            "loss: 1.831640  [  768/ 4708]\n",
            "loss: 1.846002  [ 1408/ 4708]\n",
            "loss: 1.848206  [ 2048/ 4708]\n",
            "loss: 1.859970  [ 2688/ 4708]\n",
            "loss: 1.838957  [ 3328/ 4708]\n",
            "loss: 1.845798  [ 3968/ 4708]\n",
            "loss: 1.882793  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 239\n",
            "-------------------------------\n",
            "loss: 1.839640  [  128/ 4708]\n",
            "loss: 1.860000  [  768/ 4708]\n",
            "loss: 1.849307  [ 1408/ 4708]\n",
            "loss: 1.854138  [ 2048/ 4708]\n",
            "loss: 1.851703  [ 2688/ 4708]\n",
            "loss: 1.859889  [ 3328/ 4708]\n",
            "loss: 1.854066  [ 3968/ 4708]\n",
            "loss: 1.825146  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 240\n",
            "-------------------------------\n",
            "loss: 1.843441  [  128/ 4708]\n",
            "loss: 1.872878  [  768/ 4708]\n",
            "loss: 1.849509  [ 1408/ 4708]\n",
            "loss: 1.845980  [ 2048/ 4708]\n",
            "loss: 1.864694  [ 2688/ 4708]\n",
            "loss: 1.852542  [ 3328/ 4708]\n",
            "loss: 1.871131  [ 3968/ 4708]\n",
            "loss: 1.827629  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 241\n",
            "-------------------------------\n",
            "loss: 1.851452  [  128/ 4708]\n",
            "loss: 1.820380  [  768/ 4708]\n",
            "loss: 1.845518  [ 1408/ 4708]\n",
            "loss: 1.822395  [ 2048/ 4708]\n",
            "loss: 1.834359  [ 2688/ 4708]\n",
            "loss: 1.838997  [ 3328/ 4708]\n",
            "loss: 1.837765  [ 3968/ 4708]\n",
            "loss: 1.866617  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 242\n",
            "-------------------------------\n",
            "loss: 1.831348  [  128/ 4708]\n",
            "loss: 1.844841  [  768/ 4708]\n",
            "loss: 1.844343  [ 1408/ 4708]\n",
            "loss: 1.867455  [ 2048/ 4708]\n",
            "loss: 1.870091  [ 2688/ 4708]\n",
            "loss: 1.857238  [ 3328/ 4708]\n",
            "loss: 1.863596  [ 3968/ 4708]\n",
            "loss: 1.867108  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 243\n",
            "-------------------------------\n",
            "loss: 1.861612  [  128/ 4708]\n",
            "loss: 1.857069  [  768/ 4708]\n",
            "loss: 1.846970  [ 1408/ 4708]\n",
            "loss: 1.858841  [ 2048/ 4708]\n",
            "loss: 1.836980  [ 2688/ 4708]\n",
            "loss: 1.857432  [ 3328/ 4708]\n",
            "loss: 1.848184  [ 3968/ 4708]\n",
            "loss: 1.856743  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 244\n",
            "-------------------------------\n",
            "loss: 1.844034  [  128/ 4708]\n",
            "loss: 1.860939  [  768/ 4708]\n",
            "loss: 1.849812  [ 1408/ 4708]\n",
            "loss: 1.872763  [ 2048/ 4708]\n",
            "loss: 1.872168  [ 2688/ 4708]\n",
            "loss: 1.839085  [ 3328/ 4708]\n",
            "loss: 1.826421  [ 3968/ 4708]\n",
            "loss: 1.823392  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 245\n",
            "-------------------------------\n",
            "loss: 1.878726  [  128/ 4708]\n",
            "loss: 1.834984  [  768/ 4708]\n",
            "loss: 1.840858  [ 1408/ 4708]\n",
            "loss: 1.847939  [ 2048/ 4708]\n",
            "loss: 1.833432  [ 2688/ 4708]\n",
            "loss: 1.812845  [ 3328/ 4708]\n",
            "loss: 1.863842  [ 3968/ 4708]\n",
            "loss: 1.856743  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 246\n",
            "-------------------------------\n",
            "loss: 1.873233  [  128/ 4708]\n",
            "loss: 1.863875  [  768/ 4708]\n",
            "loss: 1.860503  [ 1408/ 4708]\n",
            "loss: 1.860382  [ 2048/ 4708]\n",
            "loss: 1.830032  [ 2688/ 4708]\n",
            "loss: 1.845213  [ 3328/ 4708]\n",
            "loss: 1.839652  [ 3968/ 4708]\n",
            "loss: 1.828074  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 247\n",
            "-------------------------------\n",
            "loss: 1.837550  [  128/ 4708]\n",
            "loss: 1.858993  [  768/ 4708]\n",
            "loss: 1.814202  [ 1408/ 4708]\n",
            "loss: 1.807403  [ 2048/ 4708]\n",
            "loss: 1.879806  [ 2688/ 4708]\n",
            "loss: 1.847309  [ 3328/ 4708]\n",
            "loss: 1.829477  [ 3968/ 4708]\n",
            "loss: 1.862428  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 248\n",
            "-------------------------------\n",
            "loss: 1.853192  [  128/ 4708]\n",
            "loss: 1.856762  [  768/ 4708]\n",
            "loss: 1.826102  [ 1408/ 4708]\n",
            "loss: 1.855332  [ 2048/ 4708]\n",
            "loss: 1.855331  [ 2688/ 4708]\n",
            "loss: 1.842456  [ 3328/ 4708]\n",
            "loss: 1.837234  [ 3968/ 4708]\n",
            "loss: 1.852686  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 249\n",
            "-------------------------------\n",
            "loss: 1.844356  [  128/ 4708]\n",
            "loss: 1.814802  [  768/ 4708]\n",
            "loss: 1.840546  [ 1408/ 4708]\n",
            "loss: 1.825136  [ 2048/ 4708]\n",
            "loss: 1.840207  [ 2688/ 4708]\n",
            "loss: 1.859187  [ 3328/ 4708]\n",
            "loss: 1.858004  [ 3968/ 4708]\n",
            "loss: 1.829962  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 250\n",
            "-------------------------------\n",
            "loss: 1.849492  [  128/ 4708]\n",
            "loss: 1.859841  [  768/ 4708]\n",
            "loss: 1.840971  [ 1408/ 4708]\n",
            "loss: 1.839412  [ 2048/ 4708]\n",
            "loss: 1.845699  [ 2688/ 4708]\n",
            "loss: 1.834399  [ 3328/ 4708]\n",
            "loss: 1.877369  [ 3968/ 4708]\n",
            "loss: 1.873790  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 251\n",
            "-------------------------------\n",
            "loss: 1.832063  [  128/ 4708]\n",
            "loss: 1.826664  [  768/ 4708]\n",
            "loss: 1.868014  [ 1408/ 4708]\n",
            "loss: 1.861957  [ 2048/ 4708]\n",
            "loss: 1.857634  [ 2688/ 4708]\n",
            "loss: 1.827633  [ 3328/ 4708]\n",
            "loss: 1.845389  [ 3968/ 4708]\n",
            "loss: 1.846731  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 252\n",
            "-------------------------------\n",
            "loss: 1.869709  [  128/ 4708]\n",
            "loss: 1.850960  [  768/ 4708]\n",
            "loss: 1.840130  [ 1408/ 4708]\n",
            "loss: 1.847190  [ 2048/ 4708]\n",
            "loss: 1.853546  [ 2688/ 4708]\n",
            "loss: 1.848126  [ 3328/ 4708]\n",
            "loss: 1.860508  [ 3968/ 4708]\n",
            "loss: 1.837141  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 253\n",
            "-------------------------------\n",
            "loss: 1.828922  [  128/ 4708]\n",
            "loss: 1.822195  [  768/ 4708]\n",
            "loss: 1.867321  [ 1408/ 4708]\n",
            "loss: 1.860137  [ 2048/ 4708]\n",
            "loss: 1.827081  [ 2688/ 4708]\n",
            "loss: 1.852360  [ 3328/ 4708]\n",
            "loss: 1.835233  [ 3968/ 4708]\n",
            "loss: 1.832247  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 254\n",
            "-------------------------------\n",
            "loss: 1.834577  [  128/ 4708]\n",
            "loss: 1.843453  [  768/ 4708]\n",
            "loss: 1.861539  [ 1408/ 4708]\n",
            "loss: 1.826439  [ 2048/ 4708]\n",
            "loss: 1.860460  [ 2688/ 4708]\n",
            "loss: 1.835620  [ 3328/ 4708]\n",
            "loss: 1.858139  [ 3968/ 4708]\n",
            "loss: 1.859754  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 255\n",
            "-------------------------------\n",
            "loss: 1.852379  [  128/ 4708]\n",
            "loss: 1.841338  [  768/ 4708]\n",
            "loss: 1.838511  [ 1408/ 4708]\n",
            "loss: 1.866507  [ 2048/ 4708]\n",
            "loss: 1.835593  [ 2688/ 4708]\n",
            "loss: 1.806212  [ 3328/ 4708]\n",
            "loss: 1.860051  [ 3968/ 4708]\n",
            "loss: 1.883688  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 256\n",
            "-------------------------------\n",
            "loss: 1.866897  [  128/ 4708]\n",
            "loss: 1.827045  [  768/ 4708]\n",
            "loss: 1.822143  [ 1408/ 4708]\n",
            "loss: 1.844951  [ 2048/ 4708]\n",
            "loss: 1.877071  [ 2688/ 4708]\n",
            "loss: 1.845737  [ 3328/ 4708]\n",
            "loss: 1.823249  [ 3968/ 4708]\n",
            "loss: 1.859008  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 257\n",
            "-------------------------------\n",
            "loss: 1.850804  [  128/ 4708]\n",
            "loss: 1.811860  [  768/ 4708]\n",
            "loss: 1.866937  [ 1408/ 4708]\n",
            "loss: 1.825766  [ 2048/ 4708]\n",
            "loss: 1.842788  [ 2688/ 4708]\n",
            "loss: 1.880694  [ 3328/ 4708]\n",
            "loss: 1.864760  [ 3968/ 4708]\n",
            "loss: 1.825736  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 258\n",
            "-------------------------------\n",
            "loss: 1.822436  [  128/ 4708]\n",
            "loss: 1.838386  [  768/ 4708]\n",
            "loss: 1.849392  [ 1408/ 4708]\n",
            "loss: 1.883332  [ 2048/ 4708]\n",
            "loss: 1.891031  [ 2688/ 4708]\n",
            "loss: 1.839319  [ 3328/ 4708]\n",
            "loss: 1.825146  [ 3968/ 4708]\n",
            "loss: 1.839165  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 259\n",
            "-------------------------------\n",
            "loss: 1.827986  [  128/ 4708]\n",
            "loss: 1.856918  [  768/ 4708]\n",
            "loss: 1.847430  [ 1408/ 4708]\n",
            "loss: 1.851197  [ 2048/ 4708]\n",
            "loss: 1.851880  [ 2688/ 4708]\n",
            "loss: 1.844418  [ 3328/ 4708]\n",
            "loss: 1.840401  [ 3968/ 4708]\n",
            "loss: 1.835000  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 260\n",
            "-------------------------------\n",
            "loss: 1.846730  [  128/ 4708]\n",
            "loss: 1.831165  [  768/ 4708]\n",
            "loss: 1.859733  [ 1408/ 4708]\n",
            "loss: 1.837425  [ 2048/ 4708]\n",
            "loss: 1.838520  [ 2688/ 4708]\n",
            "loss: 1.841173  [ 3328/ 4708]\n",
            "loss: 1.850319  [ 3968/ 4708]\n",
            "loss: 1.873723  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 261\n",
            "-------------------------------\n",
            "loss: 1.812159  [  128/ 4708]\n",
            "loss: 1.857668  [  768/ 4708]\n",
            "loss: 1.820329  [ 1408/ 4708]\n",
            "loss: 1.865370  [ 2048/ 4708]\n",
            "loss: 1.829944  [ 2688/ 4708]\n",
            "loss: 1.825342  [ 3328/ 4708]\n",
            "loss: 1.834392  [ 3968/ 4708]\n",
            "loss: 1.842602  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 262\n",
            "-------------------------------\n",
            "loss: 1.841434  [  128/ 4708]\n",
            "loss: 1.833745  [  768/ 4708]\n",
            "loss: 1.861716  [ 1408/ 4708]\n",
            "loss: 1.846250  [ 2048/ 4708]\n",
            "loss: 1.848140  [ 2688/ 4708]\n",
            "loss: 1.877925  [ 3328/ 4708]\n",
            "loss: 1.839996  [ 3968/ 4708]\n",
            "loss: 1.852374  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 263\n",
            "-------------------------------\n",
            "loss: 1.873124  [  128/ 4708]\n",
            "loss: 1.852427  [  768/ 4708]\n",
            "loss: 1.858512  [ 1408/ 4708]\n",
            "loss: 1.831352  [ 2048/ 4708]\n",
            "loss: 1.837789  [ 2688/ 4708]\n",
            "loss: 1.835012  [ 3328/ 4708]\n",
            "loss: 1.864981  [ 3968/ 4708]\n",
            "loss: 1.848725  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 264\n",
            "-------------------------------\n",
            "loss: 1.825311  [  128/ 4708]\n",
            "loss: 1.838907  [  768/ 4708]\n",
            "loss: 1.859289  [ 1408/ 4708]\n",
            "loss: 1.819116  [ 2048/ 4708]\n",
            "loss: 1.820397  [ 2688/ 4708]\n",
            "loss: 1.837681  [ 3328/ 4708]\n",
            "loss: 1.865223  [ 3968/ 4708]\n",
            "loss: 1.856153  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 265\n",
            "-------------------------------\n",
            "loss: 1.851779  [  128/ 4708]\n",
            "loss: 1.870949  [  768/ 4708]\n",
            "loss: 1.851261  [ 1408/ 4708]\n",
            "loss: 1.865959  [ 2048/ 4708]\n",
            "loss: 1.849771  [ 2688/ 4708]\n",
            "loss: 1.871831  [ 3328/ 4708]\n",
            "loss: 1.833023  [ 3968/ 4708]\n",
            "loss: 1.838530  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 266\n",
            "-------------------------------\n",
            "loss: 1.832349  [  128/ 4708]\n",
            "loss: 1.853234  [  768/ 4708]\n",
            "loss: 1.864981  [ 1408/ 4708]\n",
            "loss: 1.839527  [ 2048/ 4708]\n",
            "loss: 1.852964  [ 2688/ 4708]\n",
            "loss: 1.858577  [ 3328/ 4708]\n",
            "loss: 1.854559  [ 3968/ 4708]\n",
            "loss: 1.843328  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 267\n",
            "-------------------------------\n",
            "loss: 1.841301  [  128/ 4708]\n",
            "loss: 1.869942  [  768/ 4708]\n",
            "loss: 1.876173  [ 1408/ 4708]\n",
            "loss: 1.867114  [ 2048/ 4708]\n",
            "loss: 1.852607  [ 2688/ 4708]\n",
            "loss: 1.829645  [ 3328/ 4708]\n",
            "loss: 1.838427  [ 3968/ 4708]\n",
            "loss: 1.867995  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 268\n",
            "-------------------------------\n",
            "loss: 1.851722  [  128/ 4708]\n",
            "loss: 1.836707  [  768/ 4708]\n",
            "loss: 1.856252  [ 1408/ 4708]\n",
            "loss: 1.870743  [ 2048/ 4708]\n",
            "loss: 1.852403  [ 2688/ 4708]\n",
            "loss: 1.803479  [ 3328/ 4708]\n",
            "loss: 1.867798  [ 3968/ 4708]\n",
            "loss: 1.861681  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 269\n",
            "-------------------------------\n",
            "loss: 1.844862  [  128/ 4708]\n",
            "loss: 1.826252  [  768/ 4708]\n",
            "loss: 1.863523  [ 1408/ 4708]\n",
            "loss: 1.869298  [ 2048/ 4708]\n",
            "loss: 1.847468  [ 2688/ 4708]\n",
            "loss: 1.857121  [ 3328/ 4708]\n",
            "loss: 1.841373  [ 3968/ 4708]\n",
            "loss: 1.833858  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 270\n",
            "-------------------------------\n",
            "loss: 1.851379  [  128/ 4708]\n",
            "loss: 1.833002  [  768/ 4708]\n",
            "loss: 1.857721  [ 1408/ 4708]\n",
            "loss: 1.862337  [ 2048/ 4708]\n",
            "loss: 1.866890  [ 2688/ 4708]\n",
            "loss: 1.838361  [ 3328/ 4708]\n",
            "loss: 1.879489  [ 3968/ 4708]\n",
            "loss: 1.857458  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 271\n",
            "-------------------------------\n",
            "loss: 1.867089  [  128/ 4708]\n",
            "loss: 1.851588  [  768/ 4708]\n",
            "loss: 1.824103  [ 1408/ 4708]\n",
            "loss: 1.863158  [ 2048/ 4708]\n",
            "loss: 1.849146  [ 2688/ 4708]\n",
            "loss: 1.843326  [ 3328/ 4708]\n",
            "loss: 1.871083  [ 3968/ 4708]\n",
            "loss: 1.842121  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 272\n",
            "-------------------------------\n",
            "loss: 1.849433  [  128/ 4708]\n",
            "loss: 1.850034  [  768/ 4708]\n",
            "loss: 1.878635  [ 1408/ 4708]\n",
            "loss: 1.856296  [ 2048/ 4708]\n",
            "loss: 1.845389  [ 2688/ 4708]\n",
            "loss: 1.845369  [ 3328/ 4708]\n",
            "loss: 1.846484  [ 3968/ 4708]\n",
            "loss: 1.823964  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 273\n",
            "-------------------------------\n",
            "loss: 1.849581  [  128/ 4708]\n",
            "loss: 1.833635  [  768/ 4708]\n",
            "loss: 1.877044  [ 1408/ 4708]\n",
            "loss: 1.839677  [ 2048/ 4708]\n",
            "loss: 1.874220  [ 2688/ 4708]\n",
            "loss: 1.829139  [ 3328/ 4708]\n",
            "loss: 1.837730  [ 3968/ 4708]\n",
            "loss: 1.854803  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 274\n",
            "-------------------------------\n",
            "loss: 1.837515  [  128/ 4708]\n",
            "loss: 1.836972  [  768/ 4708]\n",
            "loss: 1.841993  [ 1408/ 4708]\n",
            "loss: 1.860839  [ 2048/ 4708]\n",
            "loss: 1.867799  [ 2688/ 4708]\n",
            "loss: 1.856503  [ 3328/ 4708]\n",
            "loss: 1.869694  [ 3968/ 4708]\n",
            "loss: 1.854102  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 275\n",
            "-------------------------------\n",
            "loss: 1.887133  [  128/ 4708]\n",
            "loss: 1.850990  [  768/ 4708]\n",
            "loss: 1.863300  [ 1408/ 4708]\n",
            "loss: 1.848210  [ 2048/ 4708]\n",
            "loss: 1.835837  [ 2688/ 4708]\n",
            "loss: 1.857559  [ 3328/ 4708]\n",
            "loss: 1.857695  [ 3968/ 4708]\n",
            "loss: 1.829259  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 276\n",
            "-------------------------------\n",
            "loss: 1.859797  [  128/ 4708]\n",
            "loss: 1.865649  [  768/ 4708]\n",
            "loss: 1.860561  [ 1408/ 4708]\n",
            "loss: 1.859719  [ 2048/ 4708]\n",
            "loss: 1.864390  [ 2688/ 4708]\n",
            "loss: 1.855288  [ 3328/ 4708]\n",
            "loss: 1.832758  [ 3968/ 4708]\n",
            "loss: 1.836883  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 277\n",
            "-------------------------------\n",
            "loss: 1.848912  [  128/ 4708]\n",
            "loss: 1.852819  [  768/ 4708]\n",
            "loss: 1.876520  [ 1408/ 4708]\n",
            "loss: 1.850777  [ 2048/ 4708]\n",
            "loss: 1.877236  [ 2688/ 4708]\n",
            "loss: 1.827012  [ 3328/ 4708]\n",
            "loss: 1.861546  [ 3968/ 4708]\n",
            "loss: 1.838936  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 278\n",
            "-------------------------------\n",
            "loss: 1.831413  [  128/ 4708]\n",
            "loss: 1.849955  [  768/ 4708]\n",
            "loss: 1.825632  [ 1408/ 4708]\n",
            "loss: 1.827717  [ 2048/ 4708]\n",
            "loss: 1.856183  [ 2688/ 4708]\n",
            "loss: 1.831061  [ 3328/ 4708]\n",
            "loss: 1.877377  [ 3968/ 4708]\n",
            "loss: 1.848920  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 279\n",
            "-------------------------------\n",
            "loss: 1.850073  [  128/ 4708]\n",
            "loss: 1.839324  [  768/ 4708]\n",
            "loss: 1.842380  [ 1408/ 4708]\n",
            "loss: 1.822065  [ 2048/ 4708]\n",
            "loss: 1.829313  [ 2688/ 4708]\n",
            "loss: 1.861009  [ 3328/ 4708]\n",
            "loss: 1.860880  [ 3968/ 4708]\n",
            "loss: 1.849507  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 280\n",
            "-------------------------------\n",
            "loss: 1.840567  [  128/ 4708]\n",
            "loss: 1.840866  [  768/ 4708]\n",
            "loss: 1.863854  [ 1408/ 4708]\n",
            "loss: 1.826735  [ 2048/ 4708]\n",
            "loss: 1.824948  [ 2688/ 4708]\n",
            "loss: 1.849802  [ 3328/ 4708]\n",
            "loss: 1.909555  [ 3968/ 4708]\n",
            "loss: 1.847977  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 281\n",
            "-------------------------------\n",
            "loss: 1.831977  [  128/ 4708]\n",
            "loss: 1.857140  [  768/ 4708]\n",
            "loss: 1.862308  [ 1408/ 4708]\n",
            "loss: 1.845755  [ 2048/ 4708]\n",
            "loss: 1.829672  [ 2688/ 4708]\n",
            "loss: 1.838216  [ 3328/ 4708]\n",
            "loss: 1.845667  [ 3968/ 4708]\n",
            "loss: 1.858605  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 282\n",
            "-------------------------------\n",
            "loss: 1.844829  [  128/ 4708]\n",
            "loss: 1.832260  [  768/ 4708]\n",
            "loss: 1.837872  [ 1408/ 4708]\n",
            "loss: 1.893082  [ 2048/ 4708]\n",
            "loss: 1.857389  [ 2688/ 4708]\n",
            "loss: 1.838114  [ 3328/ 4708]\n",
            "loss: 1.811542  [ 3968/ 4708]\n",
            "loss: 1.869637  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 283\n",
            "-------------------------------\n",
            "loss: 1.834943  [  128/ 4708]\n",
            "loss: 1.861508  [  768/ 4708]\n",
            "loss: 1.820264  [ 1408/ 4708]\n",
            "loss: 1.840097  [ 2048/ 4708]\n",
            "loss: 1.857710  [ 2688/ 4708]\n",
            "loss: 1.870049  [ 3328/ 4708]\n",
            "loss: 1.839646  [ 3968/ 4708]\n",
            "loss: 1.824867  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 284\n",
            "-------------------------------\n",
            "loss: 1.856036  [  128/ 4708]\n",
            "loss: 1.838383  [  768/ 4708]\n",
            "loss: 1.847429  [ 1408/ 4708]\n",
            "loss: 1.849498  [ 2048/ 4708]\n",
            "loss: 1.841193  [ 2688/ 4708]\n",
            "loss: 1.832690  [ 3328/ 4708]\n",
            "loss: 1.839164  [ 3968/ 4708]\n",
            "loss: 1.860523  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 285\n",
            "-------------------------------\n",
            "loss: 1.819406  [  128/ 4708]\n",
            "loss: 1.841701  [  768/ 4708]\n",
            "loss: 1.826788  [ 1408/ 4708]\n",
            "loss: 1.849146  [ 2048/ 4708]\n",
            "loss: 1.832333  [ 2688/ 4708]\n",
            "loss: 1.857602  [ 3328/ 4708]\n",
            "loss: 1.842743  [ 3968/ 4708]\n",
            "loss: 1.833976  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 286\n",
            "-------------------------------\n",
            "loss: 1.853405  [  128/ 4708]\n",
            "loss: 1.853877  [  768/ 4708]\n",
            "loss: 1.868731  [ 1408/ 4708]\n",
            "loss: 1.842298  [ 2048/ 4708]\n",
            "loss: 1.841140  [ 2688/ 4708]\n",
            "loss: 1.853721  [ 3328/ 4708]\n",
            "loss: 1.841732  [ 3968/ 4708]\n",
            "loss: 1.855696  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 287\n",
            "-------------------------------\n",
            "loss: 1.857828  [  128/ 4708]\n",
            "loss: 1.826104  [  768/ 4708]\n",
            "loss: 1.859674  [ 1408/ 4708]\n",
            "loss: 1.847380  [ 2048/ 4708]\n",
            "loss: 1.844272  [ 2688/ 4708]\n",
            "loss: 1.845001  [ 3328/ 4708]\n",
            "loss: 1.856944  [ 3968/ 4708]\n",
            "loss: 1.861780  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 288\n",
            "-------------------------------\n",
            "loss: 1.822017  [  128/ 4708]\n",
            "loss: 1.885269  [  768/ 4708]\n",
            "loss: 1.797634  [ 1408/ 4708]\n",
            "loss: 1.829156  [ 2048/ 4708]\n",
            "loss: 1.869179  [ 2688/ 4708]\n",
            "loss: 1.829251  [ 3328/ 4708]\n",
            "loss: 1.844864  [ 3968/ 4708]\n",
            "loss: 1.861905  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 289\n",
            "-------------------------------\n",
            "loss: 1.858607  [  128/ 4708]\n",
            "loss: 1.867923  [  768/ 4708]\n",
            "loss: 1.809223  [ 1408/ 4708]\n",
            "loss: 1.869508  [ 2048/ 4708]\n",
            "loss: 1.861130  [ 2688/ 4708]\n",
            "loss: 1.876500  [ 3328/ 4708]\n",
            "loss: 1.841530  [ 3968/ 4708]\n",
            "loss: 1.855631  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 290\n",
            "-------------------------------\n",
            "loss: 1.829845  [  128/ 4708]\n",
            "loss: 1.833114  [  768/ 4708]\n",
            "loss: 1.858190  [ 1408/ 4708]\n",
            "loss: 1.871923  [ 2048/ 4708]\n",
            "loss: 1.856957  [ 2688/ 4708]\n",
            "loss: 1.864138  [ 3328/ 4708]\n",
            "loss: 1.833862  [ 3968/ 4708]\n",
            "loss: 1.857628  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 291\n",
            "-------------------------------\n",
            "loss: 1.832144  [  128/ 4708]\n",
            "loss: 1.853829  [  768/ 4708]\n",
            "loss: 1.851924  [ 1408/ 4708]\n",
            "loss: 1.871088  [ 2048/ 4708]\n",
            "loss: 1.858256  [ 2688/ 4708]\n",
            "loss: 1.845712  [ 3328/ 4708]\n",
            "loss: 1.842135  [ 3968/ 4708]\n",
            "loss: 1.864210  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 292\n",
            "-------------------------------\n",
            "loss: 1.862693  [  128/ 4708]\n",
            "loss: 1.849678  [  768/ 4708]\n",
            "loss: 1.832936  [ 1408/ 4708]\n",
            "loss: 1.816022  [ 2048/ 4708]\n",
            "loss: 1.840589  [ 2688/ 4708]\n",
            "loss: 1.833938  [ 3328/ 4708]\n",
            "loss: 1.870396  [ 3968/ 4708]\n",
            "loss: 1.840744  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 293\n",
            "-------------------------------\n",
            "loss: 1.849090  [  128/ 4708]\n",
            "loss: 1.872010  [  768/ 4708]\n",
            "loss: 1.842759  [ 1408/ 4708]\n",
            "loss: 1.875710  [ 2048/ 4708]\n",
            "loss: 1.829595  [ 2688/ 4708]\n",
            "loss: 1.861343  [ 3328/ 4708]\n",
            "loss: 1.859499  [ 3968/ 4708]\n",
            "loss: 1.849223  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 294\n",
            "-------------------------------\n",
            "loss: 1.865370  [  128/ 4708]\n",
            "loss: 1.861048  [  768/ 4708]\n",
            "loss: 1.859170  [ 1408/ 4708]\n",
            "loss: 1.844075  [ 2048/ 4708]\n",
            "loss: 1.836184  [ 2688/ 4708]\n",
            "loss: 1.859005  [ 3328/ 4708]\n",
            "loss: 1.845461  [ 3968/ 4708]\n",
            "loss: 1.853366  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 295\n",
            "-------------------------------\n",
            "loss: 1.860674  [  128/ 4708]\n",
            "loss: 1.840759  [  768/ 4708]\n",
            "loss: 1.853360  [ 1408/ 4708]\n",
            "loss: 1.874756  [ 2048/ 4708]\n",
            "loss: 1.877471  [ 2688/ 4708]\n",
            "loss: 1.874816  [ 3328/ 4708]\n",
            "loss: 1.875331  [ 3968/ 4708]\n",
            "loss: 1.861697  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 296\n",
            "-------------------------------\n",
            "loss: 1.845271  [  128/ 4708]\n",
            "loss: 1.865787  [  768/ 4708]\n",
            "loss: 1.832806  [ 1408/ 4708]\n",
            "loss: 1.872191  [ 2048/ 4708]\n",
            "loss: 1.856649  [ 2688/ 4708]\n",
            "loss: 1.861299  [ 3328/ 4708]\n",
            "loss: 1.856468  [ 3968/ 4708]\n",
            "loss: 1.819291  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 297\n",
            "-------------------------------\n",
            "loss: 1.872721  [  128/ 4708]\n",
            "loss: 1.858982  [  768/ 4708]\n",
            "loss: 1.835036  [ 1408/ 4708]\n",
            "loss: 1.850479  [ 2048/ 4708]\n",
            "loss: 1.858132  [ 2688/ 4708]\n",
            "loss: 1.848722  [ 3328/ 4708]\n",
            "loss: 1.858571  [ 3968/ 4708]\n",
            "loss: 1.863520  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 298\n",
            "-------------------------------\n",
            "loss: 1.834725  [  128/ 4708]\n",
            "loss: 1.871179  [  768/ 4708]\n",
            "loss: 1.854721  [ 1408/ 4708]\n",
            "loss: 1.839879  [ 2048/ 4708]\n",
            "loss: 1.851685  [ 2688/ 4708]\n",
            "loss: 1.826384  [ 3328/ 4708]\n",
            "loss: 1.858945  [ 3968/ 4708]\n",
            "loss: 1.850336  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 299\n",
            "-------------------------------\n",
            "loss: 1.844622  [  128/ 4708]\n",
            "loss: 1.815330  [  768/ 4708]\n",
            "loss: 1.878508  [ 1408/ 4708]\n",
            "loss: 1.865954  [ 2048/ 4708]\n",
            "loss: 1.857337  [ 2688/ 4708]\n",
            "loss: 1.835214  [ 3328/ 4708]\n",
            "loss: 1.835005  [ 3968/ 4708]\n",
            "loss: 1.824848  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 300\n",
            "-------------------------------\n",
            "loss: 1.824109  [  128/ 4708]\n",
            "loss: 1.854729  [  768/ 4708]\n",
            "loss: 1.847157  [ 1408/ 4708]\n",
            "loss: 1.876801  [ 2048/ 4708]\n",
            "loss: 1.851826  [ 2688/ 4708]\n",
            "loss: 1.829141  [ 3328/ 4708]\n",
            "loss: 1.848651  [ 3968/ 4708]\n",
            "loss: 1.838167  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 301\n",
            "-------------------------------\n",
            "loss: 1.855548  [  128/ 4708]\n",
            "loss: 1.871370  [  768/ 4708]\n",
            "loss: 1.848083  [ 1408/ 4708]\n",
            "loss: 1.825930  [ 2048/ 4708]\n",
            "loss: 1.843827  [ 2688/ 4708]\n",
            "loss: 1.845369  [ 3328/ 4708]\n",
            "loss: 1.867487  [ 3968/ 4708]\n",
            "loss: 1.863586  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 302\n",
            "-------------------------------\n",
            "loss: 1.839764  [  128/ 4708]\n",
            "loss: 1.848381  [  768/ 4708]\n",
            "loss: 1.866010  [ 1408/ 4708]\n",
            "loss: 1.823282  [ 2048/ 4708]\n",
            "loss: 1.840478  [ 2688/ 4708]\n",
            "loss: 1.889509  [ 3328/ 4708]\n",
            "loss: 1.855026  [ 3968/ 4708]\n",
            "loss: 1.848107  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 303\n",
            "-------------------------------\n",
            "loss: 1.863936  [  128/ 4708]\n",
            "loss: 1.831237  [  768/ 4708]\n",
            "loss: 1.855814  [ 1408/ 4708]\n",
            "loss: 1.830509  [ 2048/ 4708]\n",
            "loss: 1.885780  [ 2688/ 4708]\n",
            "loss: 1.846360  [ 3328/ 4708]\n",
            "loss: 1.871675  [ 3968/ 4708]\n",
            "loss: 1.875836  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 304\n",
            "-------------------------------\n",
            "loss: 1.830313  [  128/ 4708]\n",
            "loss: 1.844910  [  768/ 4708]\n",
            "loss: 1.850277  [ 1408/ 4708]\n",
            "loss: 1.853642  [ 2048/ 4708]\n",
            "loss: 1.828522  [ 2688/ 4708]\n",
            "loss: 1.872901  [ 3328/ 4708]\n",
            "loss: 1.855257  [ 3968/ 4708]\n",
            "loss: 1.853311  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 305\n",
            "-------------------------------\n",
            "loss: 1.850331  [  128/ 4708]\n",
            "loss: 1.824349  [  768/ 4708]\n",
            "loss: 1.830176  [ 1408/ 4708]\n",
            "loss: 1.827687  [ 2048/ 4708]\n",
            "loss: 1.817434  [ 2688/ 4708]\n",
            "loss: 1.852350  [ 3328/ 4708]\n",
            "loss: 1.860907  [ 3968/ 4708]\n",
            "loss: 1.840481  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 306\n",
            "-------------------------------\n",
            "loss: 1.838575  [  128/ 4708]\n",
            "loss: 1.857042  [  768/ 4708]\n",
            "loss: 1.840505  [ 1408/ 4708]\n",
            "loss: 1.835559  [ 2048/ 4708]\n",
            "loss: 1.872631  [ 2688/ 4708]\n",
            "loss: 1.852661  [ 3328/ 4708]\n",
            "loss: 1.853995  [ 3968/ 4708]\n",
            "loss: 1.864896  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 307\n",
            "-------------------------------\n",
            "loss: 1.850324  [  128/ 4708]\n",
            "loss: 1.883342  [  768/ 4708]\n",
            "loss: 1.880476  [ 1408/ 4708]\n",
            "loss: 1.834455  [ 2048/ 4708]\n",
            "loss: 1.846725  [ 2688/ 4708]\n",
            "loss: 1.836369  [ 3328/ 4708]\n",
            "loss: 1.859485  [ 3968/ 4708]\n",
            "loss: 1.855162  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 308\n",
            "-------------------------------\n",
            "loss: 1.826747  [  128/ 4708]\n",
            "loss: 1.863618  [  768/ 4708]\n",
            "loss: 1.827658  [ 1408/ 4708]\n",
            "loss: 1.832216  [ 2048/ 4708]\n",
            "loss: 1.849162  [ 2688/ 4708]\n",
            "loss: 1.856921  [ 3328/ 4708]\n",
            "loss: 1.861866  [ 3968/ 4708]\n",
            "loss: 1.842766  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 309\n",
            "-------------------------------\n",
            "loss: 1.845147  [  128/ 4708]\n",
            "loss: 1.871433  [  768/ 4708]\n",
            "loss: 1.838567  [ 1408/ 4708]\n",
            "loss: 1.854182  [ 2048/ 4708]\n",
            "loss: 1.864150  [ 2688/ 4708]\n",
            "loss: 1.842133  [ 3328/ 4708]\n",
            "loss: 1.873799  [ 3968/ 4708]\n",
            "loss: 1.832362  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 310\n",
            "-------------------------------\n",
            "loss: 1.860077  [  128/ 4708]\n",
            "loss: 1.870813  [  768/ 4708]\n",
            "loss: 1.831553  [ 1408/ 4708]\n",
            "loss: 1.843521  [ 2048/ 4708]\n",
            "loss: 1.836670  [ 2688/ 4708]\n",
            "loss: 1.880082  [ 3328/ 4708]\n",
            "loss: 1.849714  [ 3968/ 4708]\n",
            "loss: 1.859388  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 311\n",
            "-------------------------------\n",
            "loss: 1.825671  [  128/ 4708]\n",
            "loss: 1.825526  [  768/ 4708]\n",
            "loss: 1.855038  [ 1408/ 4708]\n",
            "loss: 1.889806  [ 2048/ 4708]\n",
            "loss: 1.869865  [ 2688/ 4708]\n",
            "loss: 1.894731  [ 3328/ 4708]\n",
            "loss: 1.839734  [ 3968/ 4708]\n",
            "loss: 1.838103  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 312\n",
            "-------------------------------\n",
            "loss: 1.829537  [  128/ 4708]\n",
            "loss: 1.855935  [  768/ 4708]\n",
            "loss: 1.832197  [ 1408/ 4708]\n",
            "loss: 1.870522  [ 2048/ 4708]\n",
            "loss: 1.830767  [ 2688/ 4708]\n",
            "loss: 1.833848  [ 3328/ 4708]\n",
            "loss: 1.846128  [ 3968/ 4708]\n",
            "loss: 1.843054  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 313\n",
            "-------------------------------\n",
            "loss: 1.826270  [  128/ 4708]\n",
            "loss: 1.854200  [  768/ 4708]\n",
            "loss: 1.862821  [ 1408/ 4708]\n",
            "loss: 1.828176  [ 2048/ 4708]\n",
            "loss: 1.851384  [ 2688/ 4708]\n",
            "loss: 1.822959  [ 3328/ 4708]\n",
            "loss: 1.841751  [ 3968/ 4708]\n",
            "loss: 1.837834  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 314\n",
            "-------------------------------\n",
            "loss: 1.853498  [  128/ 4708]\n",
            "loss: 1.848529  [  768/ 4708]\n",
            "loss: 1.840629  [ 1408/ 4708]\n",
            "loss: 1.872540  [ 2048/ 4708]\n",
            "loss: 1.836938  [ 2688/ 4708]\n",
            "loss: 1.894830  [ 3328/ 4708]\n",
            "loss: 1.860150  [ 3968/ 4708]\n",
            "loss: 1.835886  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 315\n",
            "-------------------------------\n",
            "loss: 1.860354  [  128/ 4708]\n",
            "loss: 1.852635  [  768/ 4708]\n",
            "loss: 1.842334  [ 1408/ 4708]\n",
            "loss: 1.860504  [ 2048/ 4708]\n",
            "loss: 1.857851  [ 2688/ 4708]\n",
            "loss: 1.855750  [ 3328/ 4708]\n",
            "loss: 1.860206  [ 3968/ 4708]\n",
            "loss: 1.858816  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 316\n",
            "-------------------------------\n",
            "loss: 1.841055  [  128/ 4708]\n",
            "loss: 1.835785  [  768/ 4708]\n",
            "loss: 1.847727  [ 1408/ 4708]\n",
            "loss: 1.870625  [ 2048/ 4708]\n",
            "loss: 1.878175  [ 2688/ 4708]\n",
            "loss: 1.868739  [ 3328/ 4708]\n",
            "loss: 1.864470  [ 3968/ 4708]\n",
            "loss: 1.866862  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 317\n",
            "-------------------------------\n",
            "loss: 1.885284  [  128/ 4708]\n",
            "loss: 1.820629  [  768/ 4708]\n",
            "loss: 1.837025  [ 1408/ 4708]\n",
            "loss: 1.828735  [ 2048/ 4708]\n",
            "loss: 1.846270  [ 2688/ 4708]\n",
            "loss: 1.839764  [ 3328/ 4708]\n",
            "loss: 1.864387  [ 3968/ 4708]\n",
            "loss: 1.871692  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 318\n",
            "-------------------------------\n",
            "loss: 1.824932  [  128/ 4708]\n",
            "loss: 1.819246  [  768/ 4708]\n",
            "loss: 1.836064  [ 1408/ 4708]\n",
            "loss: 1.851792  [ 2048/ 4708]\n",
            "loss: 1.825297  [ 2688/ 4708]\n",
            "loss: 1.843876  [ 3328/ 4708]\n",
            "loss: 1.849115  [ 3968/ 4708]\n",
            "loss: 1.856210  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 319\n",
            "-------------------------------\n",
            "loss: 1.873652  [  128/ 4708]\n",
            "loss: 1.862047  [  768/ 4708]\n",
            "loss: 1.856355  [ 1408/ 4708]\n",
            "loss: 1.846657  [ 2048/ 4708]\n",
            "loss: 1.834147  [ 2688/ 4708]\n",
            "loss: 1.836632  [ 3328/ 4708]\n",
            "loss: 1.842614  [ 3968/ 4708]\n",
            "loss: 1.873587  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 320\n",
            "-------------------------------\n",
            "loss: 1.865596  [  128/ 4708]\n",
            "loss: 1.870582  [  768/ 4708]\n",
            "loss: 1.844223  [ 1408/ 4708]\n",
            "loss: 1.834910  [ 2048/ 4708]\n",
            "loss: 1.850847  [ 2688/ 4708]\n",
            "loss: 1.848491  [ 3328/ 4708]\n",
            "loss: 1.850578  [ 3968/ 4708]\n",
            "loss: 1.879516  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 321\n",
            "-------------------------------\n",
            "loss: 1.862095  [  128/ 4708]\n",
            "loss: 1.821246  [  768/ 4708]\n",
            "loss: 1.866635  [ 1408/ 4708]\n",
            "loss: 1.850132  [ 2048/ 4708]\n",
            "loss: 1.835833  [ 2688/ 4708]\n",
            "loss: 1.866640  [ 3328/ 4708]\n",
            "loss: 1.840053  [ 3968/ 4708]\n",
            "loss: 1.854891  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 322\n",
            "-------------------------------\n",
            "loss: 1.878377  [  128/ 4708]\n",
            "loss: 1.844382  [  768/ 4708]\n",
            "loss: 1.843385  [ 1408/ 4708]\n",
            "loss: 1.845032  [ 2048/ 4708]\n",
            "loss: 1.867478  [ 2688/ 4708]\n",
            "loss: 1.854665  [ 3328/ 4708]\n",
            "loss: 1.825018  [ 3968/ 4708]\n",
            "loss: 1.862608  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 323\n",
            "-------------------------------\n",
            "loss: 1.856624  [  128/ 4708]\n",
            "loss: 1.829535  [  768/ 4708]\n",
            "loss: 1.843251  [ 1408/ 4708]\n",
            "loss: 1.847332  [ 2048/ 4708]\n",
            "loss: 1.840765  [ 2688/ 4708]\n",
            "loss: 1.845361  [ 3328/ 4708]\n",
            "loss: 1.827480  [ 3968/ 4708]\n",
            "loss: 1.855464  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 324\n",
            "-------------------------------\n",
            "loss: 1.861945  [  128/ 4708]\n",
            "loss: 1.843977  [  768/ 4708]\n",
            "loss: 1.842129  [ 1408/ 4708]\n",
            "loss: 1.837849  [ 2048/ 4708]\n",
            "loss: 1.852329  [ 2688/ 4708]\n",
            "loss: 1.852886  [ 3328/ 4708]\n",
            "loss: 1.845059  [ 3968/ 4708]\n",
            "loss: 1.858757  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 325\n",
            "-------------------------------\n",
            "loss: 1.837206  [  128/ 4708]\n",
            "loss: 1.845377  [  768/ 4708]\n",
            "loss: 1.865278  [ 1408/ 4708]\n",
            "loss: 1.852536  [ 2048/ 4708]\n",
            "loss: 1.851586  [ 2688/ 4708]\n",
            "loss: 1.858921  [ 3328/ 4708]\n",
            "loss: 1.855233  [ 3968/ 4708]\n",
            "loss: 1.848349  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 326\n",
            "-------------------------------\n",
            "loss: 1.838264  [  128/ 4708]\n",
            "loss: 1.842860  [  768/ 4708]\n",
            "loss: 1.849563  [ 1408/ 4708]\n",
            "loss: 1.870606  [ 2048/ 4708]\n",
            "loss: 1.846336  [ 2688/ 4708]\n",
            "loss: 1.882657  [ 3328/ 4708]\n",
            "loss: 1.855501  [ 3968/ 4708]\n",
            "loss: 1.867158  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 327\n",
            "-------------------------------\n",
            "loss: 1.850105  [  128/ 4708]\n",
            "loss: 1.834810  [  768/ 4708]\n",
            "loss: 1.860415  [ 1408/ 4708]\n",
            "loss: 1.899169  [ 2048/ 4708]\n",
            "loss: 1.859945  [ 2688/ 4708]\n",
            "loss: 1.829209  [ 3328/ 4708]\n",
            "loss: 1.834660  [ 3968/ 4708]\n",
            "loss: 1.852394  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 328\n",
            "-------------------------------\n",
            "loss: 1.835412  [  128/ 4708]\n",
            "loss: 1.836480  [  768/ 4708]\n",
            "loss: 1.816988  [ 1408/ 4708]\n",
            "loss: 1.839997  [ 2048/ 4708]\n",
            "loss: 1.837376  [ 2688/ 4708]\n",
            "loss: 1.844736  [ 3328/ 4708]\n",
            "loss: 1.855665  [ 3968/ 4708]\n",
            "loss: 1.872655  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 329\n",
            "-------------------------------\n",
            "loss: 1.836824  [  128/ 4708]\n",
            "loss: 1.861737  [  768/ 4708]\n",
            "loss: 1.838545  [ 1408/ 4708]\n",
            "loss: 1.882341  [ 2048/ 4708]\n",
            "loss: 1.849867  [ 2688/ 4708]\n",
            "loss: 1.830058  [ 3328/ 4708]\n",
            "loss: 1.855940  [ 3968/ 4708]\n",
            "loss: 1.824531  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 330\n",
            "-------------------------------\n",
            "loss: 1.805334  [  128/ 4708]\n",
            "loss: 1.852522  [  768/ 4708]\n",
            "loss: 1.819726  [ 1408/ 4708]\n",
            "loss: 1.846816  [ 2048/ 4708]\n",
            "loss: 1.852977  [ 2688/ 4708]\n",
            "loss: 1.859714  [ 3328/ 4708]\n",
            "loss: 1.863633  [ 3968/ 4708]\n",
            "loss: 1.873524  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 331\n",
            "-------------------------------\n",
            "loss: 1.827234  [  128/ 4708]\n",
            "loss: 1.863973  [  768/ 4708]\n",
            "loss: 1.847801  [ 1408/ 4708]\n",
            "loss: 1.832585  [ 2048/ 4708]\n",
            "loss: 1.858032  [ 2688/ 4708]\n",
            "loss: 1.845563  [ 3328/ 4708]\n",
            "loss: 1.878108  [ 3968/ 4708]\n",
            "loss: 1.865878  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 332\n",
            "-------------------------------\n",
            "loss: 1.843907  [  128/ 4708]\n",
            "loss: 1.832692  [  768/ 4708]\n",
            "loss: 1.838760  [ 1408/ 4708]\n",
            "loss: 1.868110  [ 2048/ 4708]\n",
            "loss: 1.849671  [ 2688/ 4708]\n",
            "loss: 1.851745  [ 3328/ 4708]\n",
            "loss: 1.856027  [ 3968/ 4708]\n",
            "loss: 1.818287  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 333\n",
            "-------------------------------\n",
            "loss: 1.834189  [  128/ 4708]\n",
            "loss: 1.865112  [  768/ 4708]\n",
            "loss: 1.844367  [ 1408/ 4708]\n",
            "loss: 1.831368  [ 2048/ 4708]\n",
            "loss: 1.841478  [ 2688/ 4708]\n",
            "loss: 1.837682  [ 3328/ 4708]\n",
            "loss: 1.863813  [ 3968/ 4708]\n",
            "loss: 1.866887  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 334\n",
            "-------------------------------\n",
            "loss: 1.835517  [  128/ 4708]\n",
            "loss: 1.842359  [  768/ 4708]\n",
            "loss: 1.873125  [ 1408/ 4708]\n",
            "loss: 1.837001  [ 2048/ 4708]\n",
            "loss: 1.837770  [ 2688/ 4708]\n",
            "loss: 1.847846  [ 3328/ 4708]\n",
            "loss: 1.824739  [ 3968/ 4708]\n",
            "loss: 1.869101  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 335\n",
            "-------------------------------\n",
            "loss: 1.850356  [  128/ 4708]\n",
            "loss: 1.853147  [  768/ 4708]\n",
            "loss: 1.835355  [ 1408/ 4708]\n",
            "loss: 1.834188  [ 2048/ 4708]\n",
            "loss: 1.815729  [ 2688/ 4708]\n",
            "loss: 1.820341  [ 3328/ 4708]\n",
            "loss: 1.841842  [ 3968/ 4708]\n",
            "loss: 1.858070  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 336\n",
            "-------------------------------\n",
            "loss: 1.847092  [  128/ 4708]\n",
            "loss: 1.887859  [  768/ 4708]\n",
            "loss: 1.823614  [ 1408/ 4708]\n",
            "loss: 1.841577  [ 2048/ 4708]\n",
            "loss: 1.834583  [ 2688/ 4708]\n",
            "loss: 1.864447  [ 3328/ 4708]\n",
            "loss: 1.861903  [ 3968/ 4708]\n",
            "loss: 1.852017  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 337\n",
            "-------------------------------\n",
            "loss: 1.862039  [  128/ 4708]\n",
            "loss: 1.824512  [  768/ 4708]\n",
            "loss: 1.858872  [ 1408/ 4708]\n",
            "loss: 1.848652  [ 2048/ 4708]\n",
            "loss: 1.866913  [ 2688/ 4708]\n",
            "loss: 1.855535  [ 3328/ 4708]\n",
            "loss: 1.864598  [ 3968/ 4708]\n",
            "loss: 1.846776  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 338\n",
            "-------------------------------\n",
            "loss: 1.877626  [  128/ 4708]\n",
            "loss: 1.837273  [  768/ 4708]\n",
            "loss: 1.830868  [ 1408/ 4708]\n",
            "loss: 1.852242  [ 2048/ 4708]\n",
            "loss: 1.868402  [ 2688/ 4708]\n",
            "loss: 1.837917  [ 3328/ 4708]\n",
            "loss: 1.847257  [ 3968/ 4708]\n",
            "loss: 1.849894  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 339\n",
            "-------------------------------\n",
            "loss: 1.846700  [  128/ 4708]\n",
            "loss: 1.816332  [  768/ 4708]\n",
            "loss: 1.857087  [ 1408/ 4708]\n",
            "loss: 1.868981  [ 2048/ 4708]\n",
            "loss: 1.813208  [ 2688/ 4708]\n",
            "loss: 1.832045  [ 3328/ 4708]\n",
            "loss: 1.836414  [ 3968/ 4708]\n",
            "loss: 1.843782  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 340\n",
            "-------------------------------\n",
            "loss: 1.827387  [  128/ 4708]\n",
            "loss: 1.859555  [  768/ 4708]\n",
            "loss: 1.842067  [ 1408/ 4708]\n",
            "loss: 1.846272  [ 2048/ 4708]\n",
            "loss: 1.849268  [ 2688/ 4708]\n",
            "loss: 1.840946  [ 3328/ 4708]\n",
            "loss: 1.848032  [ 3968/ 4708]\n",
            "loss: 1.830924  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 341\n",
            "-------------------------------\n",
            "loss: 1.836529  [  128/ 4708]\n",
            "loss: 1.829702  [  768/ 4708]\n",
            "loss: 1.847918  [ 1408/ 4708]\n",
            "loss: 1.831675  [ 2048/ 4708]\n",
            "loss: 1.878603  [ 2688/ 4708]\n",
            "loss: 1.850930  [ 3328/ 4708]\n",
            "loss: 1.846694  [ 3968/ 4708]\n",
            "loss: 1.852816  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 342\n",
            "-------------------------------\n",
            "loss: 1.834839  [  128/ 4708]\n",
            "loss: 1.821581  [  768/ 4708]\n",
            "loss: 1.847290  [ 1408/ 4708]\n",
            "loss: 1.854692  [ 2048/ 4708]\n",
            "loss: 1.846005  [ 2688/ 4708]\n",
            "loss: 1.877737  [ 3328/ 4708]\n",
            "loss: 1.841878  [ 3968/ 4708]\n",
            "loss: 1.845672  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 343\n",
            "-------------------------------\n",
            "loss: 1.832788  [  128/ 4708]\n",
            "loss: 1.859429  [  768/ 4708]\n",
            "loss: 1.871697  [ 1408/ 4708]\n",
            "loss: 1.833336  [ 2048/ 4708]\n",
            "loss: 1.823410  [ 2688/ 4708]\n",
            "loss: 1.852244  [ 3328/ 4708]\n",
            "loss: 1.847405  [ 3968/ 4708]\n",
            "loss: 1.861336  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 344\n",
            "-------------------------------\n",
            "loss: 1.852445  [  128/ 4708]\n",
            "loss: 1.823048  [  768/ 4708]\n",
            "loss: 1.871773  [ 1408/ 4708]\n",
            "loss: 1.890176  [ 2048/ 4708]\n",
            "loss: 1.834260  [ 2688/ 4708]\n",
            "loss: 1.830231  [ 3328/ 4708]\n",
            "loss: 1.849618  [ 3968/ 4708]\n",
            "loss: 1.863584  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 345\n",
            "-------------------------------\n",
            "loss: 1.858221  [  128/ 4708]\n",
            "loss: 1.881457  [  768/ 4708]\n",
            "loss: 1.841908  [ 1408/ 4708]\n",
            "loss: 1.859023  [ 2048/ 4708]\n",
            "loss: 1.829732  [ 2688/ 4708]\n",
            "loss: 1.842944  [ 3328/ 4708]\n",
            "loss: 1.818203  [ 3968/ 4708]\n",
            "loss: 1.866574  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 346\n",
            "-------------------------------\n",
            "loss: 1.833544  [  128/ 4708]\n",
            "loss: 1.834547  [  768/ 4708]\n",
            "loss: 1.869828  [ 1408/ 4708]\n",
            "loss: 1.878657  [ 2048/ 4708]\n",
            "loss: 1.837497  [ 2688/ 4708]\n",
            "loss: 1.869467  [ 3328/ 4708]\n",
            "loss: 1.809697  [ 3968/ 4708]\n",
            "loss: 1.818948  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 347\n",
            "-------------------------------\n",
            "loss: 1.829815  [  128/ 4708]\n",
            "loss: 1.824226  [  768/ 4708]\n",
            "loss: 1.873352  [ 1408/ 4708]\n",
            "loss: 1.821106  [ 2048/ 4708]\n",
            "loss: 1.864153  [ 2688/ 4708]\n",
            "loss: 1.847694  [ 3328/ 4708]\n",
            "loss: 1.870663  [ 3968/ 4708]\n",
            "loss: 1.866675  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 348\n",
            "-------------------------------\n",
            "loss: 1.876175  [  128/ 4708]\n",
            "loss: 1.846955  [  768/ 4708]\n",
            "loss: 1.841115  [ 1408/ 4708]\n",
            "loss: 1.841263  [ 2048/ 4708]\n",
            "loss: 1.848751  [ 2688/ 4708]\n",
            "loss: 1.861008  [ 3328/ 4708]\n",
            "loss: 1.858484  [ 3968/ 4708]\n",
            "loss: 1.875380  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 349\n",
            "-------------------------------\n",
            "loss: 1.829169  [  128/ 4708]\n",
            "loss: 1.863718  [  768/ 4708]\n",
            "loss: 1.854709  [ 1408/ 4708]\n",
            "loss: 1.842328  [ 2048/ 4708]\n",
            "loss: 1.863718  [ 2688/ 4708]\n",
            "loss: 1.882628  [ 3328/ 4708]\n",
            "loss: 1.829542  [ 3968/ 4708]\n",
            "loss: 1.840989  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 350\n",
            "-------------------------------\n",
            "loss: 1.835299  [  128/ 4708]\n",
            "loss: 1.869256  [  768/ 4708]\n",
            "loss: 1.840421  [ 1408/ 4708]\n",
            "loss: 1.832387  [ 2048/ 4708]\n",
            "loss: 1.828160  [ 2688/ 4708]\n",
            "loss: 1.854640  [ 3328/ 4708]\n",
            "loss: 1.826473  [ 3968/ 4708]\n",
            "loss: 1.858403  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 351\n",
            "-------------------------------\n",
            "loss: 1.841405  [  128/ 4708]\n",
            "loss: 1.841494  [  768/ 4708]\n",
            "loss: 1.832323  [ 1408/ 4708]\n",
            "loss: 1.836376  [ 2048/ 4708]\n",
            "loss: 1.866913  [ 2688/ 4708]\n",
            "loss: 1.834180  [ 3328/ 4708]\n",
            "loss: 1.854368  [ 3968/ 4708]\n",
            "loss: 1.874626  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 352\n",
            "-------------------------------\n",
            "loss: 1.819781  [  128/ 4708]\n",
            "loss: 1.843728  [  768/ 4708]\n",
            "loss: 1.842030  [ 1408/ 4708]\n",
            "loss: 1.852923  [ 2048/ 4708]\n",
            "loss: 1.855625  [ 2688/ 4708]\n",
            "loss: 1.875257  [ 3328/ 4708]\n",
            "loss: 1.888342  [ 3968/ 4708]\n",
            "loss: 1.843185  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 353\n",
            "-------------------------------\n",
            "loss: 1.846603  [  128/ 4708]\n",
            "loss: 1.839453  [  768/ 4708]\n",
            "loss: 1.852971  [ 1408/ 4708]\n",
            "loss: 1.832543  [ 2048/ 4708]\n",
            "loss: 1.836477  [ 2688/ 4708]\n",
            "loss: 1.869965  [ 3328/ 4708]\n",
            "loss: 1.829093  [ 3968/ 4708]\n",
            "loss: 1.840534  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 354\n",
            "-------------------------------\n",
            "loss: 1.823756  [  128/ 4708]\n",
            "loss: 1.831239  [  768/ 4708]\n",
            "loss: 1.869775  [ 1408/ 4708]\n",
            "loss: 1.837675  [ 2048/ 4708]\n",
            "loss: 1.863457  [ 2688/ 4708]\n",
            "loss: 1.835060  [ 3328/ 4708]\n",
            "loss: 1.854770  [ 3968/ 4708]\n",
            "loss: 1.876050  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 355\n",
            "-------------------------------\n",
            "loss: 1.833690  [  128/ 4708]\n",
            "loss: 1.855687  [  768/ 4708]\n",
            "loss: 1.870349  [ 1408/ 4708]\n",
            "loss: 1.844276  [ 2048/ 4708]\n",
            "loss: 1.822481  [ 2688/ 4708]\n",
            "loss: 1.828299  [ 3328/ 4708]\n",
            "loss: 1.843102  [ 3968/ 4708]\n",
            "loss: 1.856415  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 356\n",
            "-------------------------------\n",
            "loss: 1.876941  [  128/ 4708]\n",
            "loss: 1.832757  [  768/ 4708]\n",
            "loss: 1.849770  [ 1408/ 4708]\n",
            "loss: 1.837757  [ 2048/ 4708]\n",
            "loss: 1.857554  [ 2688/ 4708]\n",
            "loss: 1.844860  [ 3328/ 4708]\n",
            "loss: 1.836852  [ 3968/ 4708]\n",
            "loss: 1.877539  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 357\n",
            "-------------------------------\n",
            "loss: 1.843671  [  128/ 4708]\n",
            "loss: 1.831513  [  768/ 4708]\n",
            "loss: 1.846247  [ 1408/ 4708]\n",
            "loss: 1.856591  [ 2048/ 4708]\n",
            "loss: 1.843790  [ 2688/ 4708]\n",
            "loss: 1.856513  [ 3328/ 4708]\n",
            "loss: 1.833943  [ 3968/ 4708]\n",
            "loss: 1.842817  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 358\n",
            "-------------------------------\n",
            "loss: 1.847759  [  128/ 4708]\n",
            "loss: 1.848642  [  768/ 4708]\n",
            "loss: 1.849045  [ 1408/ 4708]\n",
            "loss: 1.842136  [ 2048/ 4708]\n",
            "loss: 1.850636  [ 2688/ 4708]\n",
            "loss: 1.839463  [ 3328/ 4708]\n",
            "loss: 1.842615  [ 3968/ 4708]\n",
            "loss: 1.824154  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 359\n",
            "-------------------------------\n",
            "loss: 1.857977  [  128/ 4708]\n",
            "loss: 1.850627  [  768/ 4708]\n",
            "loss: 1.839489  [ 1408/ 4708]\n",
            "loss: 1.854679  [ 2048/ 4708]\n",
            "loss: 1.835231  [ 2688/ 4708]\n",
            "loss: 1.872721  [ 3328/ 4708]\n",
            "loss: 1.845606  [ 3968/ 4708]\n",
            "loss: 1.849345  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 360\n",
            "-------------------------------\n",
            "loss: 1.853718  [  128/ 4708]\n",
            "loss: 1.862867  [  768/ 4708]\n",
            "loss: 1.821427  [ 1408/ 4708]\n",
            "loss: 1.855804  [ 2048/ 4708]\n",
            "loss: 1.844397  [ 2688/ 4708]\n",
            "loss: 1.835013  [ 3328/ 4708]\n",
            "loss: 1.865119  [ 3968/ 4708]\n",
            "loss: 1.872380  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 361\n",
            "-------------------------------\n",
            "loss: 1.857844  [  128/ 4708]\n",
            "loss: 1.833230  [  768/ 4708]\n",
            "loss: 1.837935  [ 1408/ 4708]\n",
            "loss: 1.811299  [ 2048/ 4708]\n",
            "loss: 1.864629  [ 2688/ 4708]\n",
            "loss: 1.854546  [ 3328/ 4708]\n",
            "loss: 1.820322  [ 3968/ 4708]\n",
            "loss: 1.842003  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 362\n",
            "-------------------------------\n",
            "loss: 1.871506  [  128/ 4708]\n",
            "loss: 1.830007  [  768/ 4708]\n",
            "loss: 1.848507  [ 1408/ 4708]\n",
            "loss: 1.832737  [ 2048/ 4708]\n",
            "loss: 1.849055  [ 2688/ 4708]\n",
            "loss: 1.858600  [ 3328/ 4708]\n",
            "loss: 1.852434  [ 3968/ 4708]\n",
            "loss: 1.880192  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 363\n",
            "-------------------------------\n",
            "loss: 1.853282  [  128/ 4708]\n",
            "loss: 1.870061  [  768/ 4708]\n",
            "loss: 1.824077  [ 1408/ 4708]\n",
            "loss: 1.854080  [ 2048/ 4708]\n",
            "loss: 1.831519  [ 2688/ 4708]\n",
            "loss: 1.845382  [ 3328/ 4708]\n",
            "loss: 1.884326  [ 3968/ 4708]\n",
            "loss: 1.863008  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 364\n",
            "-------------------------------\n",
            "loss: 1.806947  [  128/ 4708]\n",
            "loss: 1.857123  [  768/ 4708]\n",
            "loss: 1.843775  [ 1408/ 4708]\n",
            "loss: 1.845751  [ 2048/ 4708]\n",
            "loss: 1.887404  [ 2688/ 4708]\n",
            "loss: 1.860984  [ 3328/ 4708]\n",
            "loss: 1.851349  [ 3968/ 4708]\n",
            "loss: 1.854907  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 365\n",
            "-------------------------------\n",
            "loss: 1.854886  [  128/ 4708]\n",
            "loss: 1.829512  [  768/ 4708]\n",
            "loss: 1.849698  [ 1408/ 4708]\n",
            "loss: 1.855266  [ 2048/ 4708]\n",
            "loss: 1.830780  [ 2688/ 4708]\n",
            "loss: 1.831486  [ 3328/ 4708]\n",
            "loss: 1.807227  [ 3968/ 4708]\n",
            "loss: 1.854662  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 366\n",
            "-------------------------------\n",
            "loss: 1.839569  [  128/ 4708]\n",
            "loss: 1.851600  [  768/ 4708]\n",
            "loss: 1.834572  [ 1408/ 4708]\n",
            "loss: 1.847851  [ 2048/ 4708]\n",
            "loss: 1.864181  [ 2688/ 4708]\n",
            "loss: 1.841624  [ 3328/ 4708]\n",
            "loss: 1.843510  [ 3968/ 4708]\n",
            "loss: 1.856343  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 367\n",
            "-------------------------------\n",
            "loss: 1.864925  [  128/ 4708]\n",
            "loss: 1.854491  [  768/ 4708]\n",
            "loss: 1.862545  [ 1408/ 4708]\n",
            "loss: 1.826935  [ 2048/ 4708]\n",
            "loss: 1.848794  [ 2688/ 4708]\n",
            "loss: 1.843130  [ 3328/ 4708]\n",
            "loss: 1.873334  [ 3968/ 4708]\n",
            "loss: 1.866060  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 368\n",
            "-------------------------------\n",
            "loss: 1.849321  [  128/ 4708]\n",
            "loss: 1.848436  [  768/ 4708]\n",
            "loss: 1.832585  [ 1408/ 4708]\n",
            "loss: 1.838188  [ 2048/ 4708]\n",
            "loss: 1.882644  [ 2688/ 4708]\n",
            "loss: 1.834007  [ 3328/ 4708]\n",
            "loss: 1.863928  [ 3968/ 4708]\n",
            "loss: 1.796819  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 369\n",
            "-------------------------------\n",
            "loss: 1.854749  [  128/ 4708]\n",
            "loss: 1.850558  [  768/ 4708]\n",
            "loss: 1.844277  [ 1408/ 4708]\n",
            "loss: 1.852600  [ 2048/ 4708]\n",
            "loss: 1.855666  [ 2688/ 4708]\n",
            "loss: 1.853006  [ 3328/ 4708]\n",
            "loss: 1.856161  [ 3968/ 4708]\n",
            "loss: 1.869780  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 370\n",
            "-------------------------------\n",
            "loss: 1.848044  [  128/ 4708]\n",
            "loss: 1.820774  [  768/ 4708]\n",
            "loss: 1.838445  [ 1408/ 4708]\n",
            "loss: 1.824970  [ 2048/ 4708]\n",
            "loss: 1.854665  [ 2688/ 4708]\n",
            "loss: 1.854711  [ 3328/ 4708]\n",
            "loss: 1.882425  [ 3968/ 4708]\n",
            "loss: 1.835704  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 371\n",
            "-------------------------------\n",
            "loss: 1.841763  [  128/ 4708]\n",
            "loss: 1.841620  [  768/ 4708]\n",
            "loss: 1.842576  [ 1408/ 4708]\n",
            "loss: 1.845328  [ 2048/ 4708]\n",
            "loss: 1.859022  [ 2688/ 4708]\n",
            "loss: 1.851047  [ 3328/ 4708]\n",
            "loss: 1.841604  [ 3968/ 4708]\n",
            "loss: 1.860498  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 372\n",
            "-------------------------------\n",
            "loss: 1.849947  [  128/ 4708]\n",
            "loss: 1.856781  [  768/ 4708]\n",
            "loss: 1.842060  [ 1408/ 4708]\n",
            "loss: 1.856956  [ 2048/ 4708]\n",
            "loss: 1.828813  [ 2688/ 4708]\n",
            "loss: 1.851133  [ 3328/ 4708]\n",
            "loss: 1.866880  [ 3968/ 4708]\n",
            "loss: 1.862417  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 373\n",
            "-------------------------------\n",
            "loss: 1.838835  [  128/ 4708]\n",
            "loss: 1.857485  [  768/ 4708]\n",
            "loss: 1.859327  [ 1408/ 4708]\n",
            "loss: 1.865357  [ 2048/ 4708]\n",
            "loss: 1.855854  [ 2688/ 4708]\n",
            "loss: 1.839922  [ 3328/ 4708]\n",
            "loss: 1.890002  [ 3968/ 4708]\n",
            "loss: 1.864172  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 374\n",
            "-------------------------------\n",
            "loss: 1.861162  [  128/ 4708]\n",
            "loss: 1.863367  [  768/ 4708]\n",
            "loss: 1.873207  [ 1408/ 4708]\n",
            "loss: 1.836138  [ 2048/ 4708]\n",
            "loss: 1.834835  [ 2688/ 4708]\n",
            "loss: 1.868426  [ 3328/ 4708]\n",
            "loss: 1.865922  [ 3968/ 4708]\n",
            "loss: 1.848731  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 375\n",
            "-------------------------------\n",
            "loss: 1.840038  [  128/ 4708]\n",
            "loss: 1.847426  [  768/ 4708]\n",
            "loss: 1.857327  [ 1408/ 4708]\n",
            "loss: 1.845941  [ 2048/ 4708]\n",
            "loss: 1.824796  [ 2688/ 4708]\n",
            "loss: 1.855522  [ 3328/ 4708]\n",
            "loss: 1.839106  [ 3968/ 4708]\n",
            "loss: 1.861259  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 376\n",
            "-------------------------------\n",
            "loss: 1.841580  [  128/ 4708]\n",
            "loss: 1.878520  [  768/ 4708]\n",
            "loss: 1.835988  [ 1408/ 4708]\n",
            "loss: 1.838925  [ 2048/ 4708]\n",
            "loss: 1.848111  [ 2688/ 4708]\n",
            "loss: 1.837281  [ 3328/ 4708]\n",
            "loss: 1.861799  [ 3968/ 4708]\n",
            "loss: 1.856381  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 377\n",
            "-------------------------------\n",
            "loss: 1.867845  [  128/ 4708]\n",
            "loss: 1.846726  [  768/ 4708]\n",
            "loss: 1.840146  [ 1408/ 4708]\n",
            "loss: 1.852282  [ 2048/ 4708]\n",
            "loss: 1.849222  [ 2688/ 4708]\n",
            "loss: 1.839905  [ 3328/ 4708]\n",
            "loss: 1.861278  [ 3968/ 4708]\n",
            "loss: 1.851685  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 378\n",
            "-------------------------------\n",
            "loss: 1.825603  [  128/ 4708]\n",
            "loss: 1.855678  [  768/ 4708]\n",
            "loss: 1.864648  [ 1408/ 4708]\n",
            "loss: 1.838449  [ 2048/ 4708]\n",
            "loss: 1.857822  [ 2688/ 4708]\n",
            "loss: 1.864156  [ 3328/ 4708]\n",
            "loss: 1.860740  [ 3968/ 4708]\n",
            "loss: 1.849542  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 379\n",
            "-------------------------------\n",
            "loss: 1.859951  [  128/ 4708]\n",
            "loss: 1.822124  [  768/ 4708]\n",
            "loss: 1.862768  [ 1408/ 4708]\n",
            "loss: 1.855786  [ 2048/ 4708]\n",
            "loss: 1.855961  [ 2688/ 4708]\n",
            "loss: 1.835859  [ 3328/ 4708]\n",
            "loss: 1.823148  [ 3968/ 4708]\n",
            "loss: 1.881261  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 380\n",
            "-------------------------------\n",
            "loss: 1.833215  [  128/ 4708]\n",
            "loss: 1.826145  [  768/ 4708]\n",
            "loss: 1.826884  [ 1408/ 4708]\n",
            "loss: 1.873466  [ 2048/ 4708]\n",
            "loss: 1.859027  [ 2688/ 4708]\n",
            "loss: 1.868619  [ 3328/ 4708]\n",
            "loss: 1.847750  [ 3968/ 4708]\n",
            "loss: 1.848216  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 381\n",
            "-------------------------------\n",
            "loss: 1.852351  [  128/ 4708]\n",
            "loss: 1.863195  [  768/ 4708]\n",
            "loss: 1.853552  [ 1408/ 4708]\n",
            "loss: 1.860292  [ 2048/ 4708]\n",
            "loss: 1.828771  [ 2688/ 4708]\n",
            "loss: 1.857913  [ 3328/ 4708]\n",
            "loss: 1.852096  [ 3968/ 4708]\n",
            "loss: 1.822544  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 382\n",
            "-------------------------------\n",
            "loss: 1.842200  [  128/ 4708]\n",
            "loss: 1.844100  [  768/ 4708]\n",
            "loss: 1.829927  [ 1408/ 4708]\n",
            "loss: 1.831645  [ 2048/ 4708]\n",
            "loss: 1.856603  [ 2688/ 4708]\n",
            "loss: 1.841090  [ 3328/ 4708]\n",
            "loss: 1.847179  [ 3968/ 4708]\n",
            "loss: 1.850106  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 383\n",
            "-------------------------------\n",
            "loss: 1.834336  [  128/ 4708]\n",
            "loss: 1.852650  [  768/ 4708]\n",
            "loss: 1.840164  [ 1408/ 4708]\n",
            "loss: 1.839688  [ 2048/ 4708]\n",
            "loss: 1.859002  [ 2688/ 4708]\n",
            "loss: 1.827329  [ 3328/ 4708]\n",
            "loss: 1.830629  [ 3968/ 4708]\n",
            "loss: 1.856543  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 384\n",
            "-------------------------------\n",
            "loss: 1.850811  [  128/ 4708]\n",
            "loss: 1.855522  [  768/ 4708]\n",
            "loss: 1.822156  [ 1408/ 4708]\n",
            "loss: 1.815573  [ 2048/ 4708]\n",
            "loss: 1.859004  [ 2688/ 4708]\n",
            "loss: 1.834454  [ 3328/ 4708]\n",
            "loss: 1.863119  [ 3968/ 4708]\n",
            "loss: 1.851127  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 385\n",
            "-------------------------------\n",
            "loss: 1.840030  [  128/ 4708]\n",
            "loss: 1.840221  [  768/ 4708]\n",
            "loss: 1.837299  [ 1408/ 4708]\n",
            "loss: 1.834649  [ 2048/ 4708]\n",
            "loss: 1.847664  [ 2688/ 4708]\n",
            "loss: 1.847420  [ 3328/ 4708]\n",
            "loss: 1.856988  [ 3968/ 4708]\n",
            "loss: 1.850303  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 386\n",
            "-------------------------------\n",
            "loss: 1.851451  [  128/ 4708]\n",
            "loss: 1.797351  [  768/ 4708]\n",
            "loss: 1.845443  [ 1408/ 4708]\n",
            "loss: 1.826243  [ 2048/ 4708]\n",
            "loss: 1.846652  [ 2688/ 4708]\n",
            "loss: 1.859238  [ 3328/ 4708]\n",
            "loss: 1.841229  [ 3968/ 4708]\n",
            "loss: 1.828076  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 387\n",
            "-------------------------------\n",
            "loss: 1.840851  [  128/ 4708]\n",
            "loss: 1.833115  [  768/ 4708]\n",
            "loss: 1.865854  [ 1408/ 4708]\n",
            "loss: 1.858693  [ 2048/ 4708]\n",
            "loss: 1.857482  [ 2688/ 4708]\n",
            "loss: 1.836827  [ 3328/ 4708]\n",
            "loss: 1.851267  [ 3968/ 4708]\n",
            "loss: 1.857258  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 388\n",
            "-------------------------------\n",
            "loss: 1.834399  [  128/ 4708]\n",
            "loss: 1.845994  [  768/ 4708]\n",
            "loss: 1.822693  [ 1408/ 4708]\n",
            "loss: 1.875639  [ 2048/ 4708]\n",
            "loss: 1.862083  [ 2688/ 4708]\n",
            "loss: 1.851557  [ 3328/ 4708]\n",
            "loss: 1.798047  [ 3968/ 4708]\n",
            "loss: 1.850649  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 389\n",
            "-------------------------------\n",
            "loss: 1.846548  [  128/ 4708]\n",
            "loss: 1.807308  [  768/ 4708]\n",
            "loss: 1.859783  [ 1408/ 4708]\n",
            "loss: 1.861945  [ 2048/ 4708]\n",
            "loss: 1.837266  [ 2688/ 4708]\n",
            "loss: 1.843923  [ 3328/ 4708]\n",
            "loss: 1.823921  [ 3968/ 4708]\n",
            "loss: 1.831520  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 390\n",
            "-------------------------------\n",
            "loss: 1.855789  [  128/ 4708]\n",
            "loss: 1.862591  [  768/ 4708]\n",
            "loss: 1.840578  [ 1408/ 4708]\n",
            "loss: 1.832434  [ 2048/ 4708]\n",
            "loss: 1.863647  [ 2688/ 4708]\n",
            "loss: 1.882485  [ 3328/ 4708]\n",
            "loss: 1.861801  [ 3968/ 4708]\n",
            "loss: 1.829533  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 391\n",
            "-------------------------------\n",
            "loss: 1.873111  [  128/ 4708]\n",
            "loss: 1.884722  [  768/ 4708]\n",
            "loss: 1.874968  [ 1408/ 4708]\n",
            "loss: 1.832983  [ 2048/ 4708]\n",
            "loss: 1.832237  [ 2688/ 4708]\n",
            "loss: 1.853643  [ 3328/ 4708]\n",
            "loss: 1.819124  [ 3968/ 4708]\n",
            "loss: 1.839241  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 392\n",
            "-------------------------------\n",
            "loss: 1.859458  [  128/ 4708]\n",
            "loss: 1.848291  [  768/ 4708]\n",
            "loss: 1.847218  [ 1408/ 4708]\n",
            "loss: 1.842051  [ 2048/ 4708]\n",
            "loss: 1.871565  [ 2688/ 4708]\n",
            "loss: 1.849080  [ 3328/ 4708]\n",
            "loss: 1.833622  [ 3968/ 4708]\n",
            "loss: 1.852535  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 393\n",
            "-------------------------------\n",
            "loss: 1.869685  [  128/ 4708]\n",
            "loss: 1.846546  [  768/ 4708]\n",
            "loss: 1.819974  [ 1408/ 4708]\n",
            "loss: 1.836463  [ 2048/ 4708]\n",
            "loss: 1.819556  [ 2688/ 4708]\n",
            "loss: 1.849979  [ 3328/ 4708]\n",
            "loss: 1.839008  [ 3968/ 4708]\n",
            "loss: 1.845400  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 394\n",
            "-------------------------------\n",
            "loss: 1.834936  [  128/ 4708]\n",
            "loss: 1.871001  [  768/ 4708]\n",
            "loss: 1.835052  [ 1408/ 4708]\n",
            "loss: 1.826236  [ 2048/ 4708]\n",
            "loss: 1.840138  [ 2688/ 4708]\n",
            "loss: 1.888750  [ 3328/ 4708]\n",
            "loss: 1.821494  [ 3968/ 4708]\n",
            "loss: 1.845223  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 395\n",
            "-------------------------------\n",
            "loss: 1.862779  [  128/ 4708]\n",
            "loss: 1.857105  [  768/ 4708]\n",
            "loss: 1.846453  [ 1408/ 4708]\n",
            "loss: 1.851960  [ 2048/ 4708]\n",
            "loss: 1.861147  [ 2688/ 4708]\n",
            "loss: 1.859397  [ 3328/ 4708]\n",
            "loss: 1.844304  [ 3968/ 4708]\n",
            "loss: 1.829442  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 396\n",
            "-------------------------------\n",
            "loss: 1.836717  [  128/ 4708]\n",
            "loss: 1.859738  [  768/ 4708]\n",
            "loss: 1.860504  [ 1408/ 4708]\n",
            "loss: 1.857042  [ 2048/ 4708]\n",
            "loss: 1.832309  [ 2688/ 4708]\n",
            "loss: 1.845683  [ 3328/ 4708]\n",
            "loss: 1.819376  [ 3968/ 4708]\n",
            "loss: 1.868235  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 397\n",
            "-------------------------------\n",
            "loss: 1.865949  [  128/ 4708]\n",
            "loss: 1.850283  [  768/ 4708]\n",
            "loss: 1.852434  [ 1408/ 4708]\n",
            "loss: 1.837295  [ 2048/ 4708]\n",
            "loss: 1.819449  [ 2688/ 4708]\n",
            "loss: 1.848733  [ 3328/ 4708]\n",
            "loss: 1.839184  [ 3968/ 4708]\n",
            "loss: 1.885320  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 398\n",
            "-------------------------------\n",
            "loss: 1.856883  [  128/ 4708]\n",
            "loss: 1.822198  [  768/ 4708]\n",
            "loss: 1.822925  [ 1408/ 4708]\n",
            "loss: 1.874472  [ 2048/ 4708]\n",
            "loss: 1.857086  [ 2688/ 4708]\n",
            "loss: 1.823858  [ 3328/ 4708]\n",
            "loss: 1.846608  [ 3968/ 4708]\n",
            "loss: 1.835589  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 399\n",
            "-------------------------------\n",
            "loss: 1.840043  [  128/ 4708]\n",
            "loss: 1.836108  [  768/ 4708]\n",
            "loss: 1.875934  [ 1408/ 4708]\n",
            "loss: 1.847193  [ 2048/ 4708]\n",
            "loss: 1.859588  [ 2688/ 4708]\n",
            "loss: 1.844635  [ 3328/ 4708]\n",
            "loss: 1.832624  [ 3968/ 4708]\n",
            "loss: 1.865309  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 400\n",
            "-------------------------------\n",
            "loss: 1.845304  [  128/ 4708]\n",
            "loss: 1.831654  [  768/ 4708]\n",
            "loss: 1.853523  [ 1408/ 4708]\n",
            "loss: 1.818254  [ 2048/ 4708]\n",
            "loss: 1.835800  [ 2688/ 4708]\n",
            "loss: 1.818541  [ 3328/ 4708]\n",
            "loss: 1.863168  [ 3968/ 4708]\n",
            "loss: 1.869777  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 401\n",
            "-------------------------------\n",
            "loss: 1.822047  [  128/ 4708]\n",
            "loss: 1.833236  [  768/ 4708]\n",
            "loss: 1.823829  [ 1408/ 4708]\n",
            "loss: 1.844284  [ 2048/ 4708]\n",
            "loss: 1.870474  [ 2688/ 4708]\n",
            "loss: 1.869372  [ 3328/ 4708]\n",
            "loss: 1.845032  [ 3968/ 4708]\n",
            "loss: 1.830823  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 402\n",
            "-------------------------------\n",
            "loss: 1.859209  [  128/ 4708]\n",
            "loss: 1.855719  [  768/ 4708]\n",
            "loss: 1.844517  [ 1408/ 4708]\n",
            "loss: 1.842083  [ 2048/ 4708]\n",
            "loss: 1.849435  [ 2688/ 4708]\n",
            "loss: 1.867660  [ 3328/ 4708]\n",
            "loss: 1.863141  [ 3968/ 4708]\n",
            "loss: 1.849949  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 403\n",
            "-------------------------------\n",
            "loss: 1.861383  [  128/ 4708]\n",
            "loss: 1.821696  [  768/ 4708]\n",
            "loss: 1.856120  [ 1408/ 4708]\n",
            "loss: 1.828429  [ 2048/ 4708]\n",
            "loss: 1.855054  [ 2688/ 4708]\n",
            "loss: 1.843198  [ 3328/ 4708]\n",
            "loss: 1.842815  [ 3968/ 4708]\n",
            "loss: 1.834146  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 404\n",
            "-------------------------------\n",
            "loss: 1.830459  [  128/ 4708]\n",
            "loss: 1.844063  [  768/ 4708]\n",
            "loss: 1.849268  [ 1408/ 4708]\n",
            "loss: 1.873534  [ 2048/ 4708]\n",
            "loss: 1.819174  [ 2688/ 4708]\n",
            "loss: 1.846455  [ 3328/ 4708]\n",
            "loss: 1.801883  [ 3968/ 4708]\n",
            "loss: 1.840089  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 405\n",
            "-------------------------------\n",
            "loss: 1.855266  [  128/ 4708]\n",
            "loss: 1.839847  [  768/ 4708]\n",
            "loss: 1.842645  [ 1408/ 4708]\n",
            "loss: 1.838558  [ 2048/ 4708]\n",
            "loss: 1.824272  [ 2688/ 4708]\n",
            "loss: 1.868261  [ 3328/ 4708]\n",
            "loss: 1.832960  [ 3968/ 4708]\n",
            "loss: 1.857167  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 406\n",
            "-------------------------------\n",
            "loss: 1.824363  [  128/ 4708]\n",
            "loss: 1.842855  [  768/ 4708]\n",
            "loss: 1.877119  [ 1408/ 4708]\n",
            "loss: 1.869016  [ 2048/ 4708]\n",
            "loss: 1.820940  [ 2688/ 4708]\n",
            "loss: 1.837265  [ 3328/ 4708]\n",
            "loss: 1.863336  [ 3968/ 4708]\n",
            "loss: 1.864040  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 407\n",
            "-------------------------------\n",
            "loss: 1.829941  [  128/ 4708]\n",
            "loss: 1.841828  [  768/ 4708]\n",
            "loss: 1.845694  [ 1408/ 4708]\n",
            "loss: 1.865348  [ 2048/ 4708]\n",
            "loss: 1.837844  [ 2688/ 4708]\n",
            "loss: 1.857397  [ 3328/ 4708]\n",
            "loss: 1.821789  [ 3968/ 4708]\n",
            "loss: 1.867888  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 408\n",
            "-------------------------------\n",
            "loss: 1.849818  [  128/ 4708]\n",
            "loss: 1.843782  [  768/ 4708]\n",
            "loss: 1.876075  [ 1408/ 4708]\n",
            "loss: 1.889652  [ 2048/ 4708]\n",
            "loss: 1.872276  [ 2688/ 4708]\n",
            "loss: 1.868683  [ 3328/ 4708]\n",
            "loss: 1.844435  [ 3968/ 4708]\n",
            "loss: 1.881711  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 409\n",
            "-------------------------------\n",
            "loss: 1.836398  [  128/ 4708]\n",
            "loss: 1.841053  [  768/ 4708]\n",
            "loss: 1.852742  [ 1408/ 4708]\n",
            "loss: 1.824106  [ 2048/ 4708]\n",
            "loss: 1.829117  [ 2688/ 4708]\n",
            "loss: 1.855364  [ 3328/ 4708]\n",
            "loss: 1.839267  [ 3968/ 4708]\n",
            "loss: 1.854165  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 410\n",
            "-------------------------------\n",
            "loss: 1.864801  [  128/ 4708]\n",
            "loss: 1.862524  [  768/ 4708]\n",
            "loss: 1.866943  [ 1408/ 4708]\n",
            "loss: 1.879629  [ 2048/ 4708]\n",
            "loss: 1.817128  [ 2688/ 4708]\n",
            "loss: 1.860116  [ 3328/ 4708]\n",
            "loss: 1.858915  [ 3968/ 4708]\n",
            "loss: 1.857556  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 411\n",
            "-------------------------------\n",
            "loss: 1.818383  [  128/ 4708]\n",
            "loss: 1.866187  [  768/ 4708]\n",
            "loss: 1.835085  [ 1408/ 4708]\n",
            "loss: 1.841663  [ 2048/ 4708]\n",
            "loss: 1.854257  [ 2688/ 4708]\n",
            "loss: 1.831914  [ 3328/ 4708]\n",
            "loss: 1.853666  [ 3968/ 4708]\n",
            "loss: 1.865444  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 412\n",
            "-------------------------------\n",
            "loss: 1.833745  [  128/ 4708]\n",
            "loss: 1.864757  [  768/ 4708]\n",
            "loss: 1.863755  [ 1408/ 4708]\n",
            "loss: 1.861367  [ 2048/ 4708]\n",
            "loss: 1.867398  [ 2688/ 4708]\n",
            "loss: 1.847061  [ 3328/ 4708]\n",
            "loss: 1.846455  [ 3968/ 4708]\n",
            "loss: 1.834994  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 413\n",
            "-------------------------------\n",
            "loss: 1.878510  [  128/ 4708]\n",
            "loss: 1.853495  [  768/ 4708]\n",
            "loss: 1.870985  [ 1408/ 4708]\n",
            "loss: 1.846658  [ 2048/ 4708]\n",
            "loss: 1.844219  [ 2688/ 4708]\n",
            "loss: 1.836969  [ 3328/ 4708]\n",
            "loss: 1.844275  [ 3968/ 4708]\n",
            "loss: 1.829040  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 414\n",
            "-------------------------------\n",
            "loss: 1.828792  [  128/ 4708]\n",
            "loss: 1.841369  [  768/ 4708]\n",
            "loss: 1.848288  [ 1408/ 4708]\n",
            "loss: 1.860903  [ 2048/ 4708]\n",
            "loss: 1.841113  [ 2688/ 4708]\n",
            "loss: 1.867320  [ 3328/ 4708]\n",
            "loss: 1.850005  [ 3968/ 4708]\n",
            "loss: 1.855767  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 415\n",
            "-------------------------------\n",
            "loss: 1.843739  [  128/ 4708]\n",
            "loss: 1.844487  [  768/ 4708]\n",
            "loss: 1.819138  [ 1408/ 4708]\n",
            "loss: 1.863104  [ 2048/ 4708]\n",
            "loss: 1.859901  [ 2688/ 4708]\n",
            "loss: 1.831201  [ 3328/ 4708]\n",
            "loss: 1.860831  [ 3968/ 4708]\n",
            "loss: 1.850145  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 416\n",
            "-------------------------------\n",
            "loss: 1.840757  [  128/ 4708]\n",
            "loss: 1.846923  [  768/ 4708]\n",
            "loss: 1.826540  [ 1408/ 4708]\n",
            "loss: 1.842026  [ 2048/ 4708]\n",
            "loss: 1.859898  [ 2688/ 4708]\n",
            "loss: 1.833962  [ 3328/ 4708]\n",
            "loss: 1.825924  [ 3968/ 4708]\n",
            "loss: 1.842792  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 417\n",
            "-------------------------------\n",
            "loss: 1.854177  [  128/ 4708]\n",
            "loss: 1.854755  [  768/ 4708]\n",
            "loss: 1.904067  [ 1408/ 4708]\n",
            "loss: 1.849385  [ 2048/ 4708]\n",
            "loss: 1.842173  [ 2688/ 4708]\n",
            "loss: 1.822378  [ 3328/ 4708]\n",
            "loss: 1.854130  [ 3968/ 4708]\n",
            "loss: 1.819822  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 418\n",
            "-------------------------------\n",
            "loss: 1.840709  [  128/ 4708]\n",
            "loss: 1.846542  [  768/ 4708]\n",
            "loss: 1.824865  [ 1408/ 4708]\n",
            "loss: 1.845191  [ 2048/ 4708]\n",
            "loss: 1.868105  [ 2688/ 4708]\n",
            "loss: 1.830469  [ 3328/ 4708]\n",
            "loss: 1.835489  [ 3968/ 4708]\n",
            "loss: 1.874912  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 419\n",
            "-------------------------------\n",
            "loss: 1.854075  [  128/ 4708]\n",
            "loss: 1.853232  [  768/ 4708]\n",
            "loss: 1.831895  [ 1408/ 4708]\n",
            "loss: 1.845764  [ 2048/ 4708]\n",
            "loss: 1.835424  [ 2688/ 4708]\n",
            "loss: 1.826278  [ 3328/ 4708]\n",
            "loss: 1.872399  [ 3968/ 4708]\n",
            "loss: 1.845144  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 420\n",
            "-------------------------------\n",
            "loss: 1.850464  [  128/ 4708]\n",
            "loss: 1.881420  [  768/ 4708]\n",
            "loss: 1.868341  [ 1408/ 4708]\n",
            "loss: 1.852542  [ 2048/ 4708]\n",
            "loss: 1.865945  [ 2688/ 4708]\n",
            "loss: 1.834141  [ 3328/ 4708]\n",
            "loss: 1.853436  [ 3968/ 4708]\n",
            "loss: 1.845975  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 421\n",
            "-------------------------------\n",
            "loss: 1.825274  [  128/ 4708]\n",
            "loss: 1.825815  [  768/ 4708]\n",
            "loss: 1.853201  [ 1408/ 4708]\n",
            "loss: 1.830485  [ 2048/ 4708]\n",
            "loss: 1.863982  [ 2688/ 4708]\n",
            "loss: 1.846063  [ 3328/ 4708]\n",
            "loss: 1.849203  [ 3968/ 4708]\n",
            "loss: 1.836610  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 422\n",
            "-------------------------------\n",
            "loss: 1.861786  [  128/ 4708]\n",
            "loss: 1.840449  [  768/ 4708]\n",
            "loss: 1.852639  [ 1408/ 4708]\n",
            "loss: 1.849086  [ 2048/ 4708]\n",
            "loss: 1.847950  [ 2688/ 4708]\n",
            "loss: 1.864138  [ 3328/ 4708]\n",
            "loss: 1.832565  [ 3968/ 4708]\n",
            "loss: 1.868526  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 423\n",
            "-------------------------------\n",
            "loss: 1.844928  [  128/ 4708]\n",
            "loss: 1.809137  [  768/ 4708]\n",
            "loss: 1.849285  [ 1408/ 4708]\n",
            "loss: 1.871582  [ 2048/ 4708]\n",
            "loss: 1.840059  [ 2688/ 4708]\n",
            "loss: 1.854808  [ 3328/ 4708]\n",
            "loss: 1.828326  [ 3968/ 4708]\n",
            "loss: 1.875946  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 424\n",
            "-------------------------------\n",
            "loss: 1.856307  [  128/ 4708]\n",
            "loss: 1.830293  [  768/ 4708]\n",
            "loss: 1.842491  [ 1408/ 4708]\n",
            "loss: 1.826199  [ 2048/ 4708]\n",
            "loss: 1.822599  [ 2688/ 4708]\n",
            "loss: 1.855107  [ 3328/ 4708]\n",
            "loss: 1.843575  [ 3968/ 4708]\n",
            "loss: 1.885815  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 425\n",
            "-------------------------------\n",
            "loss: 1.845403  [  128/ 4708]\n",
            "loss: 1.864252  [  768/ 4708]\n",
            "loss: 1.832814  [ 1408/ 4708]\n",
            "loss: 1.867936  [ 2048/ 4708]\n",
            "loss: 1.865129  [ 2688/ 4708]\n",
            "loss: 1.862665  [ 3328/ 4708]\n",
            "loss: 1.862630  [ 3968/ 4708]\n",
            "loss: 1.850174  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 426\n",
            "-------------------------------\n",
            "loss: 1.851477  [  128/ 4708]\n",
            "loss: 1.849924  [  768/ 4708]\n",
            "loss: 1.834754  [ 1408/ 4708]\n",
            "loss: 1.853723  [ 2048/ 4708]\n",
            "loss: 1.879780  [ 2688/ 4708]\n",
            "loss: 1.825361  [ 3328/ 4708]\n",
            "loss: 1.834514  [ 3968/ 4708]\n",
            "loss: 1.847692  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 427\n",
            "-------------------------------\n",
            "loss: 1.882969  [  128/ 4708]\n",
            "loss: 1.831394  [  768/ 4708]\n",
            "loss: 1.846554  [ 1408/ 4708]\n",
            "loss: 1.843397  [ 2048/ 4708]\n",
            "loss: 1.842703  [ 2688/ 4708]\n",
            "loss: 1.844827  [ 3328/ 4708]\n",
            "loss: 1.855533  [ 3968/ 4708]\n",
            "loss: 1.845813  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 428\n",
            "-------------------------------\n",
            "loss: 1.840233  [  128/ 4708]\n",
            "loss: 1.845032  [  768/ 4708]\n",
            "loss: 1.821270  [ 1408/ 4708]\n",
            "loss: 1.871624  [ 2048/ 4708]\n",
            "loss: 1.844323  [ 2688/ 4708]\n",
            "loss: 1.853180  [ 3328/ 4708]\n",
            "loss: 1.841888  [ 3968/ 4708]\n",
            "loss: 1.854521  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 429\n",
            "-------------------------------\n",
            "loss: 1.861312  [  128/ 4708]\n",
            "loss: 1.828983  [  768/ 4708]\n",
            "loss: 1.845062  [ 1408/ 4708]\n",
            "loss: 1.832535  [ 2048/ 4708]\n",
            "loss: 1.840763  [ 2688/ 4708]\n",
            "loss: 1.846042  [ 3328/ 4708]\n",
            "loss: 1.834598  [ 3968/ 4708]\n",
            "loss: 1.854544  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 430\n",
            "-------------------------------\n",
            "loss: 1.865386  [  128/ 4708]\n",
            "loss: 1.825732  [  768/ 4708]\n",
            "loss: 1.844583  [ 1408/ 4708]\n",
            "loss: 1.841426  [ 2048/ 4708]\n",
            "loss: 1.866406  [ 2688/ 4708]\n",
            "loss: 1.828332  [ 3328/ 4708]\n",
            "loss: 1.854970  [ 3968/ 4708]\n",
            "loss: 1.822722  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 431\n",
            "-------------------------------\n",
            "loss: 1.833660  [  128/ 4708]\n",
            "loss: 1.861096  [  768/ 4708]\n",
            "loss: 1.840632  [ 1408/ 4708]\n",
            "loss: 1.883457  [ 2048/ 4708]\n",
            "loss: 1.855182  [ 2688/ 4708]\n",
            "loss: 1.852665  [ 3328/ 4708]\n",
            "loss: 1.857548  [ 3968/ 4708]\n",
            "loss: 1.853726  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 432\n",
            "-------------------------------\n",
            "loss: 1.894118  [  128/ 4708]\n",
            "loss: 1.850705  [  768/ 4708]\n",
            "loss: 1.845297  [ 1408/ 4708]\n",
            "loss: 1.861162  [ 2048/ 4708]\n",
            "loss: 1.853848  [ 2688/ 4708]\n",
            "loss: 1.851237  [ 3328/ 4708]\n",
            "loss: 1.856348  [ 3968/ 4708]\n",
            "loss: 1.844835  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 433\n",
            "-------------------------------\n",
            "loss: 1.861957  [  128/ 4708]\n",
            "loss: 1.834908  [  768/ 4708]\n",
            "loss: 1.873124  [ 1408/ 4708]\n",
            "loss: 1.839717  [ 2048/ 4708]\n",
            "loss: 1.828151  [ 2688/ 4708]\n",
            "loss: 1.841318  [ 3328/ 4708]\n",
            "loss: 1.831393  [ 3968/ 4708]\n",
            "loss: 1.836425  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 434\n",
            "-------------------------------\n",
            "loss: 1.823511  [  128/ 4708]\n",
            "loss: 1.842284  [  768/ 4708]\n",
            "loss: 1.836657  [ 1408/ 4708]\n",
            "loss: 1.846658  [ 2048/ 4708]\n",
            "loss: 1.859668  [ 2688/ 4708]\n",
            "loss: 1.845403  [ 3328/ 4708]\n",
            "loss: 1.836058  [ 3968/ 4708]\n",
            "loss: 1.863786  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 435\n",
            "-------------------------------\n",
            "loss: 1.856561  [  128/ 4708]\n",
            "loss: 1.839119  [  768/ 4708]\n",
            "loss: 1.850152  [ 1408/ 4708]\n",
            "loss: 1.838055  [ 2048/ 4708]\n",
            "loss: 1.831460  [ 2688/ 4708]\n",
            "loss: 1.892875  [ 3328/ 4708]\n",
            "loss: 1.828567  [ 3968/ 4708]\n",
            "loss: 1.865478  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 436\n",
            "-------------------------------\n",
            "loss: 1.824747  [  128/ 4708]\n",
            "loss: 1.837911  [  768/ 4708]\n",
            "loss: 1.833872  [ 1408/ 4708]\n",
            "loss: 1.859972  [ 2048/ 4708]\n",
            "loss: 1.839152  [ 2688/ 4708]\n",
            "loss: 1.864953  [ 3328/ 4708]\n",
            "loss: 1.850734  [ 3968/ 4708]\n",
            "loss: 1.839917  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 437\n",
            "-------------------------------\n",
            "loss: 1.848439  [  128/ 4708]\n",
            "loss: 1.837718  [  768/ 4708]\n",
            "loss: 1.838706  [ 1408/ 4708]\n",
            "loss: 1.883178  [ 2048/ 4708]\n",
            "loss: 1.847583  [ 2688/ 4708]\n",
            "loss: 1.859348  [ 3328/ 4708]\n",
            "loss: 1.871039  [ 3968/ 4708]\n",
            "loss: 1.866038  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 438\n",
            "-------------------------------\n",
            "loss: 1.841454  [  128/ 4708]\n",
            "loss: 1.816282  [  768/ 4708]\n",
            "loss: 1.859755  [ 1408/ 4708]\n",
            "loss: 1.833000  [ 2048/ 4708]\n",
            "loss: 1.868923  [ 2688/ 4708]\n",
            "loss: 1.845678  [ 3328/ 4708]\n",
            "loss: 1.887982  [ 3968/ 4708]\n",
            "loss: 1.865357  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 439\n",
            "-------------------------------\n",
            "loss: 1.862275  [  128/ 4708]\n",
            "loss: 1.863644  [  768/ 4708]\n",
            "loss: 1.851547  [ 1408/ 4708]\n",
            "loss: 1.827356  [ 2048/ 4708]\n",
            "loss: 1.850557  [ 2688/ 4708]\n",
            "loss: 1.821478  [ 3328/ 4708]\n",
            "loss: 1.817829  [ 3968/ 4708]\n",
            "loss: 1.828397  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 440\n",
            "-------------------------------\n",
            "loss: 1.849836  [  128/ 4708]\n",
            "loss: 1.840822  [  768/ 4708]\n",
            "loss: 1.846245  [ 1408/ 4708]\n",
            "loss: 1.859023  [ 2048/ 4708]\n",
            "loss: 1.868954  [ 2688/ 4708]\n",
            "loss: 1.839081  [ 3328/ 4708]\n",
            "loss: 1.855532  [ 3968/ 4708]\n",
            "loss: 1.856561  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 441\n",
            "-------------------------------\n",
            "loss: 1.853644  [  128/ 4708]\n",
            "loss: 1.846468  [  768/ 4708]\n",
            "loss: 1.832199  [ 1408/ 4708]\n",
            "loss: 1.876246  [ 2048/ 4708]\n",
            "loss: 1.852140  [ 2688/ 4708]\n",
            "loss: 1.872907  [ 3328/ 4708]\n",
            "loss: 1.858874  [ 3968/ 4708]\n",
            "loss: 1.861867  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 442\n",
            "-------------------------------\n",
            "loss: 1.855597  [  128/ 4708]\n",
            "loss: 1.860874  [  768/ 4708]\n",
            "loss: 1.848168  [ 1408/ 4708]\n",
            "loss: 1.850260  [ 2048/ 4708]\n",
            "loss: 1.834377  [ 2688/ 4708]\n",
            "loss: 1.858197  [ 3328/ 4708]\n",
            "loss: 1.852329  [ 3968/ 4708]\n",
            "loss: 1.826849  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 443\n",
            "-------------------------------\n",
            "loss: 1.847888  [  128/ 4708]\n",
            "loss: 1.846549  [  768/ 4708]\n",
            "loss: 1.847757  [ 1408/ 4708]\n",
            "loss: 1.860841  [ 2048/ 4708]\n",
            "loss: 1.827657  [ 2688/ 4708]\n",
            "loss: 1.833659  [ 3328/ 4708]\n",
            "loss: 1.862393  [ 3968/ 4708]\n",
            "loss: 1.865227  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 444\n",
            "-------------------------------\n",
            "loss: 1.840302  [  128/ 4708]\n",
            "loss: 1.858641  [  768/ 4708]\n",
            "loss: 1.835037  [ 1408/ 4708]\n",
            "loss: 1.858559  [ 2048/ 4708]\n",
            "loss: 1.860962  [ 2688/ 4708]\n",
            "loss: 1.844428  [ 3328/ 4708]\n",
            "loss: 1.870695  [ 3968/ 4708]\n",
            "loss: 1.865631  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 445\n",
            "-------------------------------\n",
            "loss: 1.826179  [  128/ 4708]\n",
            "loss: 1.853902  [  768/ 4708]\n",
            "loss: 1.845742  [ 1408/ 4708]\n",
            "loss: 1.876549  [ 2048/ 4708]\n",
            "loss: 1.860197  [ 2688/ 4708]\n",
            "loss: 1.851609  [ 3328/ 4708]\n",
            "loss: 1.837617  [ 3968/ 4708]\n",
            "loss: 1.849940  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 446\n",
            "-------------------------------\n",
            "loss: 1.834762  [  128/ 4708]\n",
            "loss: 1.844306  [  768/ 4708]\n",
            "loss: 1.860454  [ 1408/ 4708]\n",
            "loss: 1.844015  [ 2048/ 4708]\n",
            "loss: 1.831501  [ 2688/ 4708]\n",
            "loss: 1.847232  [ 3328/ 4708]\n",
            "loss: 1.857880  [ 3968/ 4708]\n",
            "loss: 1.860394  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 447\n",
            "-------------------------------\n",
            "loss: 1.843055  [  128/ 4708]\n",
            "loss: 1.833912  [  768/ 4708]\n",
            "loss: 1.866187  [ 1408/ 4708]\n",
            "loss: 1.864020  [ 2048/ 4708]\n",
            "loss: 1.828138  [ 2688/ 4708]\n",
            "loss: 1.853583  [ 3328/ 4708]\n",
            "loss: 1.838351  [ 3968/ 4708]\n",
            "loss: 1.841654  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 448\n",
            "-------------------------------\n",
            "loss: 1.850302  [  128/ 4708]\n",
            "loss: 1.845486  [  768/ 4708]\n",
            "loss: 1.832980  [ 1408/ 4708]\n",
            "loss: 1.870224  [ 2048/ 4708]\n",
            "loss: 1.846163  [ 2688/ 4708]\n",
            "loss: 1.847724  [ 3328/ 4708]\n",
            "loss: 1.863544  [ 3968/ 4708]\n",
            "loss: 1.845665  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 449\n",
            "-------------------------------\n",
            "loss: 1.829257  [  128/ 4708]\n",
            "loss: 1.848855  [  768/ 4708]\n",
            "loss: 1.878968  [ 1408/ 4708]\n",
            "loss: 1.825001  [ 2048/ 4708]\n",
            "loss: 1.850830  [ 2688/ 4708]\n",
            "loss: 1.876201  [ 3328/ 4708]\n",
            "loss: 1.836978  [ 3968/ 4708]\n",
            "loss: 1.847692  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 450\n",
            "-------------------------------\n",
            "loss: 1.856845  [  128/ 4708]\n",
            "loss: 1.837227  [  768/ 4708]\n",
            "loss: 1.840621  [ 1408/ 4708]\n",
            "loss: 1.849709  [ 2048/ 4708]\n",
            "loss: 1.847802  [ 2688/ 4708]\n",
            "loss: 1.859712  [ 3328/ 4708]\n",
            "loss: 1.847861  [ 3968/ 4708]\n",
            "loss: 1.846153  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 451\n",
            "-------------------------------\n",
            "loss: 1.873272  [  128/ 4708]\n",
            "loss: 1.857061  [  768/ 4708]\n",
            "loss: 1.834754  [ 1408/ 4708]\n",
            "loss: 1.862932  [ 2048/ 4708]\n",
            "loss: 1.872641  [ 2688/ 4708]\n",
            "loss: 1.863228  [ 3328/ 4708]\n",
            "loss: 1.852738  [ 3968/ 4708]\n",
            "loss: 1.834470  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 452\n",
            "-------------------------------\n",
            "loss: 1.820601  [  128/ 4708]\n",
            "loss: 1.828736  [  768/ 4708]\n",
            "loss: 1.830211  [ 1408/ 4708]\n",
            "loss: 1.847727  [ 2048/ 4708]\n",
            "loss: 1.841950  [ 2688/ 4708]\n",
            "loss: 1.856729  [ 3328/ 4708]\n",
            "loss: 1.872074  [ 3968/ 4708]\n",
            "loss: 1.861071  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 453\n",
            "-------------------------------\n",
            "loss: 1.892145  [  128/ 4708]\n",
            "loss: 1.845879  [  768/ 4708]\n",
            "loss: 1.870886  [ 1408/ 4708]\n",
            "loss: 1.859857  [ 2048/ 4708]\n",
            "loss: 1.824921  [ 2688/ 4708]\n",
            "loss: 1.857221  [ 3328/ 4708]\n",
            "loss: 1.844827  [ 3968/ 4708]\n",
            "loss: 1.864633  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 454\n",
            "-------------------------------\n",
            "loss: 1.877250  [  128/ 4708]\n",
            "loss: 1.842504  [  768/ 4708]\n",
            "loss: 1.852719  [ 1408/ 4708]\n",
            "loss: 1.834425  [ 2048/ 4708]\n",
            "loss: 1.829379  [ 2688/ 4708]\n",
            "loss: 1.845438  [ 3328/ 4708]\n",
            "loss: 1.851474  [ 3968/ 4708]\n",
            "loss: 1.813215  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 455\n",
            "-------------------------------\n",
            "loss: 1.827159  [  128/ 4708]\n",
            "loss: 1.870027  [  768/ 4708]\n",
            "loss: 1.843496  [ 1408/ 4708]\n",
            "loss: 1.868307  [ 2048/ 4708]\n",
            "loss: 1.867777  [ 2688/ 4708]\n",
            "loss: 1.839242  [ 3328/ 4708]\n",
            "loss: 1.860242  [ 3968/ 4708]\n",
            "loss: 1.882347  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 456\n",
            "-------------------------------\n",
            "loss: 1.876226  [  128/ 4708]\n",
            "loss: 1.849037  [  768/ 4708]\n",
            "loss: 1.842257  [ 1408/ 4708]\n",
            "loss: 1.870828  [ 2048/ 4708]\n",
            "loss: 1.849909  [ 2688/ 4708]\n",
            "loss: 1.860245  [ 3328/ 4708]\n",
            "loss: 1.849690  [ 3968/ 4708]\n",
            "loss: 1.849172  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 457\n",
            "-------------------------------\n",
            "loss: 1.861410  [  128/ 4708]\n",
            "loss: 1.852152  [  768/ 4708]\n",
            "loss: 1.863587  [ 1408/ 4708]\n",
            "loss: 1.862233  [ 2048/ 4708]\n",
            "loss: 1.873744  [ 2688/ 4708]\n",
            "loss: 1.850971  [ 3328/ 4708]\n",
            "loss: 1.856625  [ 3968/ 4708]\n",
            "loss: 1.837672  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 458\n",
            "-------------------------------\n",
            "loss: 1.845538  [  128/ 4708]\n",
            "loss: 1.851900  [  768/ 4708]\n",
            "loss: 1.844925  [ 1408/ 4708]\n",
            "loss: 1.862909  [ 2048/ 4708]\n",
            "loss: 1.841582  [ 2688/ 4708]\n",
            "loss: 1.853153  [ 3328/ 4708]\n",
            "loss: 1.826780  [ 3968/ 4708]\n",
            "loss: 1.854228  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 459\n",
            "-------------------------------\n",
            "loss: 1.850006  [  128/ 4708]\n",
            "loss: 1.850614  [  768/ 4708]\n",
            "loss: 1.845317  [ 1408/ 4708]\n",
            "loss: 1.858984  [ 2048/ 4708]\n",
            "loss: 1.857041  [ 2688/ 4708]\n",
            "loss: 1.857172  [ 3328/ 4708]\n",
            "loss: 1.884162  [ 3968/ 4708]\n",
            "loss: 1.853719  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 460\n",
            "-------------------------------\n",
            "loss: 1.844654  [  128/ 4708]\n",
            "loss: 1.861274  [  768/ 4708]\n",
            "loss: 1.849325  [ 1408/ 4708]\n",
            "loss: 1.815981  [ 2048/ 4708]\n",
            "loss: 1.851659  [ 2688/ 4708]\n",
            "loss: 1.866627  [ 3328/ 4708]\n",
            "loss: 1.843253  [ 3968/ 4708]\n",
            "loss: 1.844686  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 461\n",
            "-------------------------------\n",
            "loss: 1.868206  [  128/ 4708]\n",
            "loss: 1.839002  [  768/ 4708]\n",
            "loss: 1.817200  [ 1408/ 4708]\n",
            "loss: 1.845384  [ 2048/ 4708]\n",
            "loss: 1.862189  [ 2688/ 4708]\n",
            "loss: 1.821010  [ 3328/ 4708]\n",
            "loss: 1.860959  [ 3968/ 4708]\n",
            "loss: 1.831862  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 462\n",
            "-------------------------------\n",
            "loss: 1.871760  [  128/ 4708]\n",
            "loss: 1.871910  [  768/ 4708]\n",
            "loss: 1.839632  [ 1408/ 4708]\n",
            "loss: 1.851972  [ 2048/ 4708]\n",
            "loss: 1.864249  [ 2688/ 4708]\n",
            "loss: 1.827777  [ 3328/ 4708]\n",
            "loss: 1.866110  [ 3968/ 4708]\n",
            "loss: 1.840378  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 463\n",
            "-------------------------------\n",
            "loss: 1.884560  [  128/ 4708]\n",
            "loss: 1.867674  [  768/ 4708]\n",
            "loss: 1.814294  [ 1408/ 4708]\n",
            "loss: 1.847822  [ 2048/ 4708]\n",
            "loss: 1.844574  [ 2688/ 4708]\n",
            "loss: 1.849223  [ 3328/ 4708]\n",
            "loss: 1.843950  [ 3968/ 4708]\n",
            "loss: 1.845951  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 464\n",
            "-------------------------------\n",
            "loss: 1.842845  [  128/ 4708]\n",
            "loss: 1.840222  [  768/ 4708]\n",
            "loss: 1.853040  [ 1408/ 4708]\n",
            "loss: 1.872949  [ 2048/ 4708]\n",
            "loss: 1.853179  [ 2688/ 4708]\n",
            "loss: 1.845040  [ 3328/ 4708]\n",
            "loss: 1.876089  [ 3968/ 4708]\n",
            "loss: 1.887039  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 465\n",
            "-------------------------------\n",
            "loss: 1.844554  [  128/ 4708]\n",
            "loss: 1.852730  [  768/ 4708]\n",
            "loss: 1.858643  [ 1408/ 4708]\n",
            "loss: 1.815503  [ 2048/ 4708]\n",
            "loss: 1.845438  [ 2688/ 4708]\n",
            "loss: 1.817848  [ 3328/ 4708]\n",
            "loss: 1.850714  [ 3968/ 4708]\n",
            "loss: 1.849771  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 466\n",
            "-------------------------------\n",
            "loss: 1.849576  [  128/ 4708]\n",
            "loss: 1.890003  [  768/ 4708]\n",
            "loss: 1.844210  [ 1408/ 4708]\n",
            "loss: 1.855976  [ 2048/ 4708]\n",
            "loss: 1.861707  [ 2688/ 4708]\n",
            "loss: 1.837901  [ 3328/ 4708]\n",
            "loss: 1.854685  [ 3968/ 4708]\n",
            "loss: 1.802735  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 467\n",
            "-------------------------------\n",
            "loss: 1.858391  [  128/ 4708]\n",
            "loss: 1.833269  [  768/ 4708]\n",
            "loss: 1.831368  [ 1408/ 4708]\n",
            "loss: 1.831516  [ 2048/ 4708]\n",
            "loss: 1.839141  [ 2688/ 4708]\n",
            "loss: 1.840390  [ 3328/ 4708]\n",
            "loss: 1.885162  [ 3968/ 4708]\n",
            "loss: 1.851686  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 468\n",
            "-------------------------------\n",
            "loss: 1.834909  [  128/ 4708]\n",
            "loss: 1.851975  [  768/ 4708]\n",
            "loss: 1.822629  [ 1408/ 4708]\n",
            "loss: 1.862424  [ 2048/ 4708]\n",
            "loss: 1.881464  [ 2688/ 4708]\n",
            "loss: 1.844466  [ 3328/ 4708]\n",
            "loss: 1.856753  [ 3968/ 4708]\n",
            "loss: 1.864853  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 469\n",
            "-------------------------------\n",
            "loss: 1.851241  [  128/ 4708]\n",
            "loss: 1.858920  [  768/ 4708]\n",
            "loss: 1.845748  [ 1408/ 4708]\n",
            "loss: 1.826651  [ 2048/ 4708]\n",
            "loss: 1.853277  [ 2688/ 4708]\n",
            "loss: 1.873351  [ 3328/ 4708]\n",
            "loss: 1.838971  [ 3968/ 4708]\n",
            "loss: 1.848532  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 470\n",
            "-------------------------------\n",
            "loss: 1.834806  [  128/ 4708]\n",
            "loss: 1.849161  [  768/ 4708]\n",
            "loss: 1.832679  [ 1408/ 4708]\n",
            "loss: 1.805678  [ 2048/ 4708]\n",
            "loss: 1.894931  [ 2688/ 4708]\n",
            "loss: 1.847277  [ 3328/ 4708]\n",
            "loss: 1.871122  [ 3968/ 4708]\n",
            "loss: 1.851348  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 471\n",
            "-------------------------------\n",
            "loss: 1.828886  [  128/ 4708]\n",
            "loss: 1.853904  [  768/ 4708]\n",
            "loss: 1.880207  [ 1408/ 4708]\n",
            "loss: 1.833806  [ 2048/ 4708]\n",
            "loss: 1.843161  [ 2688/ 4708]\n",
            "loss: 1.873343  [ 3328/ 4708]\n",
            "loss: 1.860247  [ 3968/ 4708]\n",
            "loss: 1.845244  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 472\n",
            "-------------------------------\n",
            "loss: 1.838346  [  128/ 4708]\n",
            "loss: 1.846140  [  768/ 4708]\n",
            "loss: 1.859974  [ 1408/ 4708]\n",
            "loss: 1.860038  [ 2048/ 4708]\n",
            "loss: 1.868349  [ 2688/ 4708]\n",
            "loss: 1.848428  [ 3328/ 4708]\n",
            "loss: 1.849412  [ 3968/ 4708]\n",
            "loss: 1.844354  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 473\n",
            "-------------------------------\n",
            "loss: 1.825908  [  128/ 4708]\n",
            "loss: 1.823658  [  768/ 4708]\n",
            "loss: 1.855039  [ 1408/ 4708]\n",
            "loss: 1.856772  [ 2048/ 4708]\n",
            "loss: 1.862675  [ 2688/ 4708]\n",
            "loss: 1.876594  [ 3328/ 4708]\n",
            "loss: 1.842064  [ 3968/ 4708]\n",
            "loss: 1.882617  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 474\n",
            "-------------------------------\n",
            "loss: 1.848957  [  128/ 4708]\n",
            "loss: 1.826128  [  768/ 4708]\n",
            "loss: 1.850832  [ 1408/ 4708]\n",
            "loss: 1.872412  [ 2048/ 4708]\n",
            "loss: 1.847283  [ 2688/ 4708]\n",
            "loss: 1.820708  [ 3328/ 4708]\n",
            "loss: 1.825289  [ 3968/ 4708]\n",
            "loss: 1.880437  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 475\n",
            "-------------------------------\n",
            "loss: 1.846112  [  128/ 4708]\n",
            "loss: 1.826120  [  768/ 4708]\n",
            "loss: 1.852934  [ 1408/ 4708]\n",
            "loss: 1.834514  [ 2048/ 4708]\n",
            "loss: 1.833175  [ 2688/ 4708]\n",
            "loss: 1.850938  [ 3328/ 4708]\n",
            "loss: 1.874037  [ 3968/ 4708]\n",
            "loss: 1.845521  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 476\n",
            "-------------------------------\n",
            "loss: 1.870732  [  128/ 4708]\n",
            "loss: 1.838245  [  768/ 4708]\n",
            "loss: 1.803687  [ 1408/ 4708]\n",
            "loss: 1.845381  [ 2048/ 4708]\n",
            "loss: 1.846438  [ 2688/ 4708]\n",
            "loss: 1.832302  [ 3328/ 4708]\n",
            "loss: 1.832417  [ 3968/ 4708]\n",
            "loss: 1.873593  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 477\n",
            "-------------------------------\n",
            "loss: 1.850204  [  128/ 4708]\n",
            "loss: 1.837067  [  768/ 4708]\n",
            "loss: 1.842599  [ 1408/ 4708]\n",
            "loss: 1.853524  [ 2048/ 4708]\n",
            "loss: 1.845452  [ 2688/ 4708]\n",
            "loss: 1.866866  [ 3328/ 4708]\n",
            "loss: 1.848121  [ 3968/ 4708]\n",
            "loss: 1.862285  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 478\n",
            "-------------------------------\n",
            "loss: 1.864449  [  128/ 4708]\n",
            "loss: 1.858756  [  768/ 4708]\n",
            "loss: 1.849944  [ 1408/ 4708]\n",
            "loss: 1.830083  [ 2048/ 4708]\n",
            "loss: 1.827461  [ 2688/ 4708]\n",
            "loss: 1.831373  [ 3328/ 4708]\n",
            "loss: 1.855042  [ 3968/ 4708]\n",
            "loss: 1.866369  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 479\n",
            "-------------------------------\n",
            "loss: 1.866491  [  128/ 4708]\n",
            "loss: 1.822289  [  768/ 4708]\n",
            "loss: 1.845637  [ 1408/ 4708]\n",
            "loss: 1.823683  [ 2048/ 4708]\n",
            "loss: 1.869886  [ 2688/ 4708]\n",
            "loss: 1.848924  [ 3328/ 4708]\n",
            "loss: 1.830194  [ 3968/ 4708]\n",
            "loss: 1.850070  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 480\n",
            "-------------------------------\n",
            "loss: 1.854496  [  128/ 4708]\n",
            "loss: 1.860290  [  768/ 4708]\n",
            "loss: 1.829193  [ 1408/ 4708]\n",
            "loss: 1.845980  [ 2048/ 4708]\n",
            "loss: 1.833340  [ 2688/ 4708]\n",
            "loss: 1.845147  [ 3328/ 4708]\n",
            "loss: 1.850979  [ 3968/ 4708]\n",
            "loss: 1.838358  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 481\n",
            "-------------------------------\n",
            "loss: 1.843636  [  128/ 4708]\n",
            "loss: 1.854053  [  768/ 4708]\n",
            "loss: 1.858650  [ 1408/ 4708]\n",
            "loss: 1.830800  [ 2048/ 4708]\n",
            "loss: 1.849677  [ 2688/ 4708]\n",
            "loss: 1.851738  [ 3328/ 4708]\n",
            "loss: 1.864430  [ 3968/ 4708]\n",
            "loss: 1.870205  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 482\n",
            "-------------------------------\n",
            "loss: 1.860884  [  128/ 4708]\n",
            "loss: 1.848504  [  768/ 4708]\n",
            "loss: 1.852984  [ 1408/ 4708]\n",
            "loss: 1.842056  [ 2048/ 4708]\n",
            "loss: 1.862969  [ 2688/ 4708]\n",
            "loss: 1.841393  [ 3328/ 4708]\n",
            "loss: 1.841759  [ 3968/ 4708]\n",
            "loss: 1.851025  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 483\n",
            "-------------------------------\n",
            "loss: 1.868425  [  128/ 4708]\n",
            "loss: 1.866326  [  768/ 4708]\n",
            "loss: 1.845119  [ 1408/ 4708]\n",
            "loss: 1.859785  [ 2048/ 4708]\n",
            "loss: 1.853151  [ 2688/ 4708]\n",
            "loss: 1.833594  [ 3328/ 4708]\n",
            "loss: 1.862233  [ 3968/ 4708]\n",
            "loss: 1.814475  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 484\n",
            "-------------------------------\n",
            "loss: 1.855788  [  128/ 4708]\n",
            "loss: 1.832927  [  768/ 4708]\n",
            "loss: 1.844427  [ 1408/ 4708]\n",
            "loss: 1.861897  [ 2048/ 4708]\n",
            "loss: 1.851837  [ 2688/ 4708]\n",
            "loss: 1.838230  [ 3328/ 4708]\n",
            "loss: 1.842795  [ 3968/ 4708]\n",
            "loss: 1.841472  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 485\n",
            "-------------------------------\n",
            "loss: 1.864243  [  128/ 4708]\n",
            "loss: 1.838989  [  768/ 4708]\n",
            "loss: 1.854242  [ 1408/ 4708]\n",
            "loss: 1.861316  [ 2048/ 4708]\n",
            "loss: 1.853121  [ 2688/ 4708]\n",
            "loss: 1.806465  [ 3328/ 4708]\n",
            "loss: 1.846319  [ 3968/ 4708]\n",
            "loss: 1.832827  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 486\n",
            "-------------------------------\n",
            "loss: 1.860876  [  128/ 4708]\n",
            "loss: 1.815624  [  768/ 4708]\n",
            "loss: 1.883323  [ 1408/ 4708]\n",
            "loss: 1.854866  [ 2048/ 4708]\n",
            "loss: 1.843244  [ 2688/ 4708]\n",
            "loss: 1.864393  [ 3328/ 4708]\n",
            "loss: 1.869870  [ 3968/ 4708]\n",
            "loss: 1.836444  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 487\n",
            "-------------------------------\n",
            "loss: 1.817324  [  128/ 4708]\n",
            "loss: 1.845683  [  768/ 4708]\n",
            "loss: 1.850555  [ 1408/ 4708]\n",
            "loss: 1.831990  [ 2048/ 4708]\n",
            "loss: 1.858663  [ 2688/ 4708]\n",
            "loss: 1.838088  [ 3328/ 4708]\n",
            "loss: 1.860077  [ 3968/ 4708]\n",
            "loss: 1.867784  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 488\n",
            "-------------------------------\n",
            "loss: 1.845566  [  128/ 4708]\n",
            "loss: 1.858950  [  768/ 4708]\n",
            "loss: 1.852553  [ 1408/ 4708]\n",
            "loss: 1.845437  [ 2048/ 4708]\n",
            "loss: 1.846290  [ 2688/ 4708]\n",
            "loss: 1.850866  [ 3328/ 4708]\n",
            "loss: 1.848180  [ 3968/ 4708]\n",
            "loss: 1.872272  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 489\n",
            "-------------------------------\n",
            "loss: 1.854214  [  128/ 4708]\n",
            "loss: 1.854952  [  768/ 4708]\n",
            "loss: 1.857458  [ 1408/ 4708]\n",
            "loss: 1.853906  [ 2048/ 4708]\n",
            "loss: 1.847900  [ 2688/ 4708]\n",
            "loss: 1.853968  [ 3328/ 4708]\n",
            "loss: 1.847921  [ 3968/ 4708]\n",
            "loss: 1.864708  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 490\n",
            "-------------------------------\n",
            "loss: 1.842490  [  128/ 4708]\n",
            "loss: 1.822714  [  768/ 4708]\n",
            "loss: 1.864038  [ 1408/ 4708]\n",
            "loss: 1.839872  [ 2048/ 4708]\n",
            "loss: 1.857198  [ 2688/ 4708]\n",
            "loss: 1.853354  [ 3328/ 4708]\n",
            "loss: 1.845849  [ 3968/ 4708]\n",
            "loss: 1.851235  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 491\n",
            "-------------------------------\n",
            "loss: 1.834515  [  128/ 4708]\n",
            "loss: 1.866009  [  768/ 4708]\n",
            "loss: 1.835802  [ 1408/ 4708]\n",
            "loss: 1.861895  [ 2048/ 4708]\n",
            "loss: 1.833696  [ 2688/ 4708]\n",
            "loss: 1.816419  [ 3328/ 4708]\n",
            "loss: 1.812194  [ 3968/ 4708]\n",
            "loss: 1.833317  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 492\n",
            "-------------------------------\n",
            "loss: 1.827441  [  128/ 4708]\n",
            "loss: 1.841729  [  768/ 4708]\n",
            "loss: 1.857998  [ 1408/ 4708]\n",
            "loss: 1.835521  [ 2048/ 4708]\n",
            "loss: 1.845549  [ 2688/ 4708]\n",
            "loss: 1.889219  [ 3328/ 4708]\n",
            "loss: 1.843523  [ 3968/ 4708]\n",
            "loss: 1.865669  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 493\n",
            "-------------------------------\n",
            "loss: 1.891432  [  128/ 4708]\n",
            "loss: 1.856798  [  768/ 4708]\n",
            "loss: 1.862705  [ 1408/ 4708]\n",
            "loss: 1.848342  [ 2048/ 4708]\n",
            "loss: 1.847717  [ 2688/ 4708]\n",
            "loss: 1.846049  [ 3328/ 4708]\n",
            "loss: 1.848936  [ 3968/ 4708]\n",
            "loss: 1.829616  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 494\n",
            "-------------------------------\n",
            "loss: 1.816658  [  128/ 4708]\n",
            "loss: 1.864176  [  768/ 4708]\n",
            "loss: 1.837948  [ 1408/ 4708]\n",
            "loss: 1.840286  [ 2048/ 4708]\n",
            "loss: 1.852838  [ 2688/ 4708]\n",
            "loss: 1.865677  [ 3328/ 4708]\n",
            "loss: 1.890905  [ 3968/ 4708]\n",
            "loss: 1.842842  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 495\n",
            "-------------------------------\n",
            "loss: 1.865762  [  128/ 4708]\n",
            "loss: 1.831007  [  768/ 4708]\n",
            "loss: 1.871010  [ 1408/ 4708]\n",
            "loss: 1.824415  [ 2048/ 4708]\n",
            "loss: 1.861369  [ 2688/ 4708]\n",
            "loss: 1.838930  [ 3328/ 4708]\n",
            "loss: 1.863132  [ 3968/ 4708]\n",
            "loss: 1.831939  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 496\n",
            "-------------------------------\n",
            "loss: 1.856050  [  128/ 4708]\n",
            "loss: 1.846454  [  768/ 4708]\n",
            "loss: 1.845907  [ 1408/ 4708]\n",
            "loss: 1.829623  [ 2048/ 4708]\n",
            "loss: 1.860852  [ 2688/ 4708]\n",
            "loss: 1.856034  [ 3328/ 4708]\n",
            "loss: 1.840990  [ 3968/ 4708]\n",
            "loss: 1.850683  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 497\n",
            "-------------------------------\n",
            "loss: 1.857894  [  128/ 4708]\n",
            "loss: 1.859158  [  768/ 4708]\n",
            "loss: 1.822026  [ 1408/ 4708]\n",
            "loss: 1.834830  [ 2048/ 4708]\n",
            "loss: 1.859294  [ 2688/ 4708]\n",
            "loss: 1.850671  [ 3328/ 4708]\n",
            "loss: 1.854614  [ 3968/ 4708]\n",
            "loss: 1.837257  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 498\n",
            "-------------------------------\n",
            "loss: 1.855930  [  128/ 4708]\n",
            "loss: 1.867848  [  768/ 4708]\n",
            "loss: 1.847841  [ 1408/ 4708]\n",
            "loss: 1.847721  [ 2048/ 4708]\n",
            "loss: 1.850968  [ 2688/ 4708]\n",
            "loss: 1.821114  [ 3328/ 4708]\n",
            "loss: 1.863034  [ 3968/ 4708]\n",
            "loss: 1.853802  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 499\n",
            "-------------------------------\n",
            "loss: 1.849490  [  128/ 4708]\n",
            "loss: 1.825195  [  768/ 4708]\n",
            "loss: 1.854049  [ 1408/ 4708]\n",
            "loss: 1.847253  [ 2048/ 4708]\n",
            "loss: 1.867527  [ 2688/ 4708]\n",
            "loss: 1.833171  [ 3328/ 4708]\n",
            "loss: 1.856594  [ 3968/ 4708]\n",
            "loss: 1.850089  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Epoch 500\n",
            "-------------------------------\n",
            "loss: 1.859863  [  128/ 4708]\n",
            "loss: 1.845177  [  768/ 4708]\n",
            "loss: 1.869460  [ 1408/ 4708]\n",
            "loss: 1.825182  [ 2048/ 4708]\n",
            "loss: 1.821347  [ 2688/ 4708]\n",
            "loss: 1.844794  [ 3328/ 4708]\n",
            "loss: 1.877266  [ 3968/ 4708]\n",
            "loss: 1.849119  [ 4608/ 4708]\n",
            "Test Error: \n",
            " Accuracy: 62.50000%, Avg loss: 1.903299 \n",
            "\n",
            "Done!\n",
            "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
            "Wall time: 7.39 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"model.pth\")\n",
        "print(\"Saved PyTorch Model State to model.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94jr88QptAxB",
        "outputId": "87474a4c-8022-4786-b8e4-2934f22ad1c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved PyTorch Model State to model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork().to(device)\n",
        "model.load_state_dict(torch.load(\"model.pth\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHJdsXmftERU",
        "outputId": "f0fb93b2-5c18-424b-a18e-5a2304961fed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes = [\n",
        "    \"Negative\",\n",
        "    \"Positive\",\n",
        "]\n",
        "\n",
        "model.eval()\n",
        "x, y = test_dataset[0][0], test_dataset[0][1]\n",
        "with torch.no_grad():\n",
        "    x = x.to(device)\n",
        "    pred = model(x)\n",
        "    predicted, actual = classes[pred[0].argmax(0)], classes[y[0]]\n",
        "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDzqoYA6tInj",
        "outputId": "0176dd93-a533-4917-9871-cfcfa912d9c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: \"Positive\", Actual: \"Positive\"\n"
          ]
        }
      ]
    }
  ]
}